{"pageProps":{"slug":"4.1.3/vertx-kafka-client/java","title":"Vert.x Kafka 客户端","fallbackGitHubStars":null,"toc":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#_using_the_vert_x_kafka_client\">使用 Vert.x 的 Kafka 客户端</a></li>\n<li><a href=\"#_creating_kafka_clients\">创建 kafka 客户端</a></li>\n<li><a href=\"#_receiving_messages_from_a_topic_joining_a_consumer_group\">加入一个消费者群组并从主题中接收消息</a></li>\n<li><a href=\"#_receiving_messages_from_a_topic_requesting_specific_partitions\">请求指定主题分区以接收消息</a></li>\n<li><a href=\"#_receiving_messages_with_explicit_polling\">通过显式请求获取消息</a></li>\n<li><a href=\"#_changing_the_subscription_or_assignment\">改变订阅或主题分区的分配</a></li>\n<li><a href=\"#_getting_topic_partition_information\">获取主题分区信息</a></li>\n<li><a href=\"#_manual_offset_commit\">手动提交偏移</a></li>\n<li><a href=\"#_seeking_in_a_topic_partition\">在消息分区内查询</a></li>\n<li><a href=\"#_offset_lookup\">查询偏移</a></li>\n<li><a href=\"#_message_flow_control\">消息流控制</a></li>\n<li><a href=\"#_closing_a_consumer\">关闭消费者</a></li>\n<li><a href=\"#_sending_messages_to_a_topic\">向主题发送消息</a></li>\n<li><a href=\"#_sharing_a_producer\">公用生产者</a></li>\n<li><a href=\"#_closing_a_producer\">关闭生产者</a></li>\n<li><a href=\"#_getting_topic_partition_information_2\">获取主题分片信息</a></li>\n<li><a href=\"#_handling_errors\">处理错误</a></li>\n<li><a href=\"#_automatic_clean_up_in_verticles\">verticle 的自动清理</a></li>\n<li><a href=\"#_using_vert_x_serializersdeserializers\">使用 Vert.x 的序列化器 / 反序列化器</a></li>\n<li><a href=\"#_rxjava_3_api\">RxJava 3 接口</a></li>\n<li><a href=\"#_automatic_trace_propagation\">自动追踪传播</a></li>\n</ul>\n</div>","contents":"<h1>Vert.x Kafka 客户端</h1>\n\n<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>该组件提供了 Kafka 客户端， 可以用与给 <a href=\"https://kafka.apache.org/\">Apache Kafka</a> 集群发送信息，或从中读取信息。</p>\n</div>\n<div class=\"paragraph\">\n<p>作为消费者，接口提供了订阅主题分区，并异步地\n接收消息，或将消息作为流进行处理（甚至可以做到中止或重启数据流）的方法。</p>\n</div>\n<div class=\"paragraph\">\n<p>作为生产者，接口提供了流式向主题分区发送消息的方法。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_the_vert_x_kafka_client\"><a class=\"anchor\" href=\"#_using_the_vert_x_kafka_client\"></a>使用 Vert.x 的 Kafka 客户端</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>为了使用该组件， 需要在您的构建描述文件中的依赖配置中添加如下内容：</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Maven (在您的 <code>pom.xml</code>):</p>\n</li>\n</ul>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-xml\" data-lang=\"xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span>\n <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>io.vertx<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span>\n <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>vertx-kafka-client<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span>\n <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>4.1.3<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span></code></pre>\n</div>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Gradle (在您的 <code>build.gradle</code> 文件中):</p>\n</li>\n</ul>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-groovy\" data-lang=\"groovy\">compile io.<span class=\"hljs-attr\">vertx:</span>vertx-kafka-<span class=\"hljs-attr\">client:</span><span class=\"hljs-number\">4.1</span><span class=\"hljs-number\">.3</span></code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_creating_kafka_clients\"><a class=\"anchor\" href=\"#_creating_kafka_clients\"></a>创建 kafka 客户端</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>创建 kafka 的消费者和生产者的方式非常详细，它们都基于原生的 kafka 的客户端库工作。</p>\n</div>\n<div class=\"paragraph\">\n<p>在创建时，需要进行很多配置，这些配置可以参考\nApache Kafka 文档， 参见 <a href=\"https://kafka.apache.org/documentation/#newconsumerconfigs\">消费者</a> 和\n <a href=\"https://kafka.apache.org/documentation/#producerconfigs\">生产者</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>为了方便配置， 您可以将参数放置在一个 Map 容器中，并在调用\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html\">KafkaConsumer</a></code> 和\n<code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html\">KafkaProducer</a></code> 的静态创建方法时传入。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;group.id&quot;</span>, <span class=\"hljs-string\">&quot;my_group&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;auto.offset.reset&quot;</span>, <span class=\"hljs-string\">&quot;earliest&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;enable.auto.commit&quot;</span>, <span class=\"hljs-string\">&quot;false&quot;</span>);\n\n<span class=\"hljs-comment\">// 使用消费者和 Apache Kafka 交互</span>\nKafkaConsumer&lt;String, String&gt; consumer = KafkaConsumer.create(vertx, config);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>在以上代码中，我们传入了一个 Map 容器实例作为创建 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html\">KafkaConsumer</a></code> 对象实例时\n的参数，这样可以指定要连接的 kafka 节点列表（这里只有一个）的地址和\n每个接收到的消息的键和内容的反序列化器。</p>\n</div>\n<div class=\"paragraph\">\n<p>创建 kafka 生产者地方法也大致相同。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.serializer&quot;</span>, <span class=\"hljs-string\">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.serializer&quot;</span>, <span class=\"hljs-string\">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;acks&quot;</span>, <span class=\"hljs-string\">&quot;1&quot;</span>);\n\n<span class=\"hljs-comment\">// 使用生产者和 Apache Kafka 交互</span>\nKafkaProducer&lt;String, String&gt; producer = KafkaProducer.create(vertx, config);</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_receiving_messages_from_a_topic_joining_a_consumer_group\"><a class=\"anchor\" href=\"#_receiving_messages_from_a_topic_joining_a_consumer_group\"></a>加入一个消费者群组并从主题中接收消息</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>要开始从 kafka 的主题中接收消息， 消费者需要使用\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#subscribe-java.util.Set-\">subscribe</a></code> 方法去\n作为一个消费者群组（群组在创建时的属性设置里指定）的一员去订阅一组主题。</p>\n</div>\n<div class=\"paragraph\">\n<p>您也可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#subscribe-java.util.regex.Pattern-\">subscribe</a></code> 方法去\n指定一个正则表达式，并订阅所有匹配该正则表达式的主题。</p>\n</div>\n<div class=\"paragraph\">\n<p>为了注册一个处理器去处理接收到的消息，您需要使用\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#handler-io.vertx.core.Handler-\">handler</a></code> 方法。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;Processing key=&quot;</span> + record.key() + <span class=\"hljs-string\">&quot;,value=&quot;</span> + record.value() +\n    <span class=\"hljs-string\">&quot;,partition=&quot;</span> + record.partition() + <span class=\"hljs-string\">&quot;,offset=&quot;</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">// 订阅一组主题</span>\nSet&lt;String&gt; topics = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\ntopics.add(<span class=\"hljs-string\">&quot;topic1&quot;</span>);\ntopics.add(<span class=\"hljs-string\">&quot;topic2&quot;</span>);\ntopics.add(<span class=\"hljs-string\">&quot;topic3&quot;</span>);\nconsumer.subscribe(topics);\n\n<span class=\"hljs-comment\">// 或使用正则表达式</span>\nPattern pattern = Pattern.compile(<span class=\"hljs-string\">&quot;topic\\\\d&quot;</span>);\nconsumer.subscribe(pattern);\n\n<span class=\"hljs-comment\">// 或仅订阅一个主题</span>\nconsumer.subscribe(<span class=\"hljs-string\">&quot;a-single-topic&quot;</span>);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>您可以在调用 <code>subscribe()</code> 方法的前后注册消息处理器； 直到您调用了该方法并注册了消息处理器后，消息才会\n开始被消费。 举个例子，您可以先调用 <code>subscribe()</code> 方法，再调用 <code>seek()</code> 方法，最后调用 <code>handler()</code> 方法\n，这样您可以在一个特定的偏移处开始消费消息。</p>\n</div>\n<div class=\"paragraph\">\n<p>消息处理器也可以在订阅时注册，这样您就可以获取订阅的结果并当操作完成时\n收到通知。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;Processing key=&quot;</span> + record.key() + <span class=\"hljs-string\">&quot;,value=&quot;</span> + record.value() +\n    <span class=\"hljs-string\">&quot;,partition=&quot;</span> + record.partition() + <span class=\"hljs-string\">&quot;,offset=&quot;</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">// 订阅一组主题</span>\nSet&lt;String&gt; topics = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\ntopics.add(<span class=\"hljs-string\">&quot;topic1&quot;</span>);\ntopics.add(<span class=\"hljs-string\">&quot;topic2&quot;</span>);\ntopics.add(<span class=\"hljs-string\">&quot;topic3&quot;</span>);\nconsumer\n  .subscribe(topics)\n  .onSuccess(v -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;subscribed&quot;</span>)\n  ).onFailure(cause -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;Could not subscribe &quot;</span> + cause.getMessage())\n  );\n\n<span class=\"hljs-comment\">// 或仅订阅一个主题</span>\nconsumer\n  .subscribe(<span class=\"hljs-string\">&quot;a-single-topic&quot;</span>)\n  .onSuccess(v -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;subscribed&quot;</span>)\n  ).onFailure(cause -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;Could not subscribe &quot;</span> + cause.getMessage())\n  );</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>通过使用消费者群组，Kafka 集群会将同一个消费者群组下的其他消费者正在使用的分区\n分配给该消费者， 因此分区可以在消费者群组中传播。</p>\n</div>\n<div class=\"paragraph\">\n<p>Kafka 集群会在消费者离开集群时（此时原消费者的分区可以分配给其他消费者）或\n新的消费者加入集群时（新消费者的需要申请分区来读取）重新平衡分区。</p>\n</div>\n<div class=\"paragraph\">\n<p>您可以给 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html\">KafkaConsumer</a></code> 注册一个处理器，这样\n会在 kafka 集群给消费者分配或撤回主题分区时收到通知，使用\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#partitionsRevokedHandler-io.vertx.core.Handler-\">partitionsRevokedHandler</a></code> 和\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#partitionsAssignedHandler-io.vertx.core.Handler-\">partitionsAssignedHandler</a></code> 方法注册该处理器。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;Processing key=&quot;</span> + record.key() + <span class=\"hljs-string\">&quot;,value=&quot;</span> + record.value() +\n    <span class=\"hljs-string\">&quot;,partition=&quot;</span> + record.partition() + <span class=\"hljs-string\">&quot;,offset=&quot;</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">// 注册主题分区撤回和分配的处理器</span>\nconsumer.partitionsAssignedHandler(topicPartitions -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;Partitions assigned&quot;</span>);\n  <span class=\"hljs-keyword\">for</span> (TopicPartition topicPartition : topicPartitions) {\n    System.out.println(topicPartition.getTopic() + <span class=\"hljs-string\">&quot; &quot;</span> + topicPartition.getPartition());\n  }\n});\n\nconsumer.partitionsRevokedHandler(topicPartitions -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;Partitions revoked&quot;</span>);\n  <span class=\"hljs-keyword\">for</span> (TopicPartition topicPartition : topicPartitions) {\n    System.out.println(topicPartition.getTopic() + <span class=\"hljs-string\">&quot; &quot;</span> + topicPartition.getPartition());\n  }\n});\n\n<span class=\"hljs-comment\">// 订阅主题</span>\nconsumer\n  .subscribe(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .onSuccess(v -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;subscribed&quot;</span>)\n  ).onFailure(cause -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;Could not subscribe &quot;</span> + cause.getMessage())\n  );</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>在加入一个消费者群组接收消息后， 消费者可以选择使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#unsubscribe--\">unsubscribe</a></code> 方法\n离开群组，这样就不会再收到消息</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.unsubscribe();</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>您还可以设置一个处理器来处理退出的结果</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer\n  .unsubscribe()\n  .onSuccess(v -&gt;\n    System.out.println(<span class=\"hljs-string\">&quot;Consumer unsubscribed&quot;</span>)\n  );</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_receiving_messages_from_a_topic_requesting_specific_partitions\"><a class=\"anchor\" href=\"#_receiving_messages_from_a_topic_requesting_specific_partitions\"></a>请求指定主题分区以接收消息</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>在接收消息时，除了加入消费者群组， 消费者也可以主动请求一个\n特定的主题分区。 当消费者并不在一个消费者群组内， 那么应用就不能\n依赖 kafka 的重平衡特性。</p>\n</div>\n<div class=\"paragraph\">\n<p>您可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#assign-java.util.Set-io.vertx.core.Handler-\">assign</a></code> 方法\n去请求特定的分区。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;key=&quot;</span> + record.key() + <span class=\"hljs-string\">&quot;,value=&quot;</span> + record.value() +\n    <span class=\"hljs-string\">&quot;,partition=&quot;</span> + record.partition() + <span class=\"hljs-string\">&quot;,offset=&quot;</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">//</span>\nSet&lt;TopicPartition&gt; topicPartitions = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\ntopicPartitions.add(<span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>));\n\n<span class=\"hljs-comment\">// 请求分配特定的分区</span>\nconsumer\n  .assign(topicPartitions)\n  .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Partition assigned&quot;</span>))\n  <span class=\"hljs-comment\">// 成功后会从该分区获取消息</span>\n  .compose(v -&gt; consumer.assignment())\n  .onSuccess(partitions -&gt; {\n    <span class=\"hljs-keyword\">for</span> (TopicPartition topicPartition : partitions) {\n      System.out.println(topicPartition.getTopic() + <span class=\"hljs-string\">&quot; &quot;</span> + topicPartition.getPartition());\n    }\n  });</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>使用 <code>subscribe()</code> 方法时， 您可以在调用 <code>assign()</code> 方法之前或之后注册接收消息处理器；\n因为消息只会在两个方法都生效后才会被消费。 举个例子，您可以先调用\n<code>assign()</code> 方法， 再调用 <code>seek()</code> 方法，最后调用 <code>handler()</code> 方法，\n这样您就可以只消费特定分区的指定偏移之后的消息。</p>\n</div>\n<div class=\"paragraph\">\n<p>调用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#assignment-io.vertx.core.Handler-\">assignment</a></code> 可以让您\n获取当前分配的消息分区。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_receiving_messages_with_explicit_polling\"><a class=\"anchor\" href=\"#_receiving_messages_with_explicit_polling\"></a>通过显式请求获取消息</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>为了从 Kafka 接收消息，除了使用客户端内部自带的请求机制外， 客户端可以订阅\n主题， 并且不注册消息处理器，并使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#poll-java.time.Duration-io.vertx.core.Handler-\">poll</a></code> 方法获取消息。</p>\n</div>\n<div class=\"paragraph\">\n<p>通过这种方式， 用户的应用可以在其需要时才执行请求以获取消息，\n举个例子。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer\n  .subscribe(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .onSuccess(v -&gt; {\n    System.out.println(<span class=\"hljs-string\">&quot;Consumer subscribed&quot;</span>);\n\n    <span class=\"hljs-comment\">// 每秒请求一次</span>\n    vertx.setPeriodic(<span class=\"hljs-number\">1000</span>, timerId -&gt;\n      consumer\n        .poll(Duration.ofMillis(<span class=\"hljs-number\">100</span>))\n        .onSuccess(records -&gt; {\n          <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; records.size(); i++) {\n            KafkaConsumerRecord&lt;String, String&gt; record = records.recordAt(i);\n            System.out.println(<span class=\"hljs-string\">&quot;key=&quot;</span> + record.key() + <span class=\"hljs-string\">&quot;,value=&quot;</span> + record.value() +\n              <span class=\"hljs-string\">&quot;,partition=&quot;</span> + record.partition() + <span class=\"hljs-string\">&quot;,offset=&quot;</span> + record.offset());\n          }\n        })\n        .onFailure(cause -&gt; {\n          System.out.println(<span class=\"hljs-string\">&quot;Something went wrong when polling &quot;</span> + cause.toString());\n          cause.printStackTrace();\n\n          <span class=\"hljs-comment\">// 当发生错误时停止请求</span>\n          vertx.cancelTimer(timerId);\n        })\n    );\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>订阅成功后， 应用启动了一个定时器来执行请求并且\n周期性地从 kafka 获取消息。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_changing_the_subscription_or_assignment\"><a class=\"anchor\" href=\"#_changing_the_subscription_or_assignment\"></a>改变订阅或主题分区的分配</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>您可以在开始消费消息之后修改订阅的主题或主题分区的分配，只需要\n重新调用 <code>subscribe()</code> 方法或 <code>assign()</code> 方法。</p>\n</div>\n<div class=\"paragraph\">\n<p>请记住，由于 kafka 客户端的内部存在消息缓存， 因此很有可能在您\n调用 <code>subscribe()</code> 方法或 <code>assign()</code> 方法 <em>之后</em> ，原先的消息处理器仍然\n收到了旧的主题或分区的消息。 但是如果您使用了批处理器就不会发生这种情况：\n一旦重新调用订阅或修改方法的完成回调被触发， 那么客户端就只会收到新的主题或分区的消息。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_getting_topic_partition_information\"><a class=\"anchor\" href=\"#_getting_topic_partition_information\"></a>获取主题分区信息</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>您可以调用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#partitionsFor-java.lang.String-io.vertx.core.Handler-\">partitionsFor</a></code> 方法来获取\n特定主题的分区信息。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer\n  .partitionsFor(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .onSuccess(partitions -&gt; {\n    <span class=\"hljs-keyword\">for</span> (PartitionInfo partitionInfo : partitions) {\n      System.out.println(partitionInfo);\n    }\n  });</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>您也可以调用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#listTopics-io.vertx.core.Handler-\">listTopics</a></code> 方法获取所有当前主题的\n分区信息。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer\n  .listTopics()\n  .onSuccess(partitionsTopicMap -&gt;\n    partitionsTopicMap.forEach((topic, partitions) -&gt; {\n      System.out.println(<span class=\"hljs-string\">&quot;topic = &quot;</span> + topic);\n      System.out.println(<span class=\"hljs-string\">&quot;partitions = &quot;</span> + partitions);\n    })\n  );</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_manual_offset_commit\"><a class=\"anchor\" href=\"#_manual_offset_commit\"></a>手动提交偏移</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Apache Kafka 的消费者一般会处理最后一个读取的消息的偏移。</p>\n</div>\n<div class=\"paragraph\">\n<p>一般情况下，kafka 的客户端会自动地在每次从主题分区获取一批消息\n后通过提交操作处理。 配置参数 <code>enable.auto.commit</code> 会在客户端被创建时设置\n为 <code>true</code> 。</p>\n</div>\n<div class=\"paragraph\">\n<p>手动提交偏移，可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#commit-io.vertx.core.Handler-\">commit</a></code> 方法。\n这样可以确保 <em>至少一次</em> 提交偏移前消息已经被\n处理了。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.commit().onSuccess(v -&gt;\n  System.out.println(<span class=\"hljs-string\">&quot;Last read message offset committed&quot;</span>)\n);</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_seeking_in_a_topic_partition\"><a class=\"anchor\" href=\"#_seeking_in_a_topic_partition\"></a>在消息分区内查询</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Apache Kafka 可以保存一段时间内的消息数据，并且消费者可以在消息分区内查询\n并获取任意一条消息。</p>\n</div>\n<div class=\"paragraph\">\n<p>您可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seek-io.vertx.kafka.client.common.TopicPartition-long-\">seek</a></code> 方法来改变读取时的偏移，并移动到\n特定的位置</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// 移动特定的偏移</span>\nconsumer\n  .seek(topicPartition, <span class=\"hljs-number\">10</span>)\n  .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Seeking done&quot;</span>));</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>当消费者需要从开始处重新获取消息时，可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToBeginning-io.vertx.kafka.client.common.TopicPartition-\">seekToBeginning</a></code></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// 移动偏移到分区开头</span>\nconsumer\n  .seekToBeginning(Collections.singleton(topicPartition))\n  .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Seeking done&quot;</span>));</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>最后，<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToEnd-io.vertx.kafka.client.common.TopicPartition-\">seekToEnd</a></code> 可以用于将偏移移动到分区的结尾</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// 移动偏移到分区末尾</span>\nconsumer\n  .seekToEnd(Collections.singleton(topicPartition))\n  .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Seeking done&quot;</span>));</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>请记住，由于 kafka 客户端的内部存在消息缓存， 因此很有可能在您\n调用完 <code>seek*()</code> 方法 <em>之后</em> 原有的消息处理器仍在获取原先\n偏移处的消息。 但是如果您使用了批处理器就不会发生这种情况： 一旦\n<code>seek*()</code> 的完成回调被触发， 消息处理器就只会接收到新的偏移处的消息。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_offset_lookup\"><a class=\"anchor\" href=\"#_offset_lookup\"></a>查询偏移</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>您可以使用在 Kafka 0.10.1.1 引入的 beginningOffsets 接口来获取指定分区的\n第一个偏移。 与 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToBeginning-io.vertx.kafka.client.common.TopicPartition-\">seekToBeginning</a></code> 方法不同的是，\n该接口并不会改变当前客户端的偏移。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Set&lt;TopicPartition&gt; topicPartitions = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\nTopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition().setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>).setPartition(<span class=\"hljs-number\">0</span>);\ntopicPartitions.add(topicPartition);\n\nconsumer\n  .beginningOffsets(topicPartitions)\n  .onSuccess(results -&gt;\n    results.forEach((topic, beginningOffset) -&gt;\n      System.out.println(\n        <span class=\"hljs-string\">&quot;Beginning offset for topic=&quot;</span> + topic.getTopic() + <span class=\"hljs-string\">&quot;, partition=&quot;</span> +\n          topic.getPartition() + <span class=\"hljs-string\">&quot;, beginningOffset=&quot;</span> + beginningOffset\n      )\n    )\n  );\n\n<span class=\"hljs-comment\">// 方便地获取一个分区的偏移</span>\nconsumer\n  .beginningOffsets(topicPartition)\n  .onSuccess(beginningOffset -&gt;\n    System.out.println(\n      <span class=\"hljs-string\">&quot;Beginning offset for topic=&quot;</span> + topicPartition.getTopic() + <span class=\"hljs-string\">&quot;, partition=&quot;</span> +\n        topicPartition.getPartition() + <span class=\"hljs-string\">&quot;, beginningOffset=&quot;</span> + beginningOffset\n    )\n  );</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>您可以使用在 Kafka 0.10.1.1 引入的 endOffsets 接口来获取指定分区的\n结尾偏移。 与 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToEnd-io.vertx.kafka.client.common.TopicPartition-\">seekToEnd</a></code> 方法不同的是，\n该接口并不会改变当前客户端的偏移。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Set&lt;TopicPartition&gt; topicPartitions = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\nTopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition().setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>).setPartition(<span class=\"hljs-number\">0</span>);\ntopicPartitions.add(topicPartition);\n\nconsumer.endOffsets(topicPartitions)\n  .onSuccess(results -&gt;\n    results.forEach((topic, beginningOffset) -&gt;\n      System.out.println(\n        <span class=\"hljs-string\">&quot;End offset for topic=&quot;</span> + topic.getTopic() + <span class=\"hljs-string\">&quot;, partition=&quot;</span> +\n          topic.getPartition() + <span class=\"hljs-string\">&quot;, beginningOffset=&quot;</span> + beginningOffset\n      )\n    )\n  );\n\n<span class=\"hljs-comment\">// 方便地获取一个分区的偏移</span>\nconsumer\n  .endOffsets(topicPartition)\n  .onSuccess(endOffset -&gt;\n    System.out.println(\n      <span class=\"hljs-string\">&quot;End offset for topic=&quot;</span> + topicPartition.getTopic() + <span class=\"hljs-string\">&quot;, partition=&quot;</span> +\n        topicPartition.getPartition() + <span class=\"hljs-string\">&quot;, endOffset=&quot;</span> + endOffset\n    )\n);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>您可以使用在 Kafka 0.10.1.1 引入的 endOffsets 接口来根据时间戳获取指定分区的\n偏移。查询参数是一个 unix 时间戳，而返回的结果是满足\n摄入时间 &gt;= 给定时间条件的最小偏移。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;TopicPartition, Long&gt; topicPartitionsWithTimestamps = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nTopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition().setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>).setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// 我们想知道 60 秒前摄入消息的偏移</span>\n<span class=\"hljs-keyword\">long</span> timestamp = (System.currentTimeMillis() - <span class=\"hljs-number\">60000</span>);\n\ntopicPartitionsWithTimestamps.put(topicPartition, timestamp);\nconsumer\n  .offsetsForTimes(topicPartitionsWithTimestamps)\n  .onSuccess(results -&gt;\n    results.forEach((topic, offset) -&gt;\n      System.out.println(\n        <span class=\"hljs-string\">&quot;Offset for topic=&quot;</span> + topic.getTopic() +\n        <span class=\"hljs-string\">&quot;, partition=&quot;</span> + topic.getPartition() + <span class=\"hljs-string\">&quot;\\n&quot;</span> +\n        <span class=\"hljs-string\">&quot;, timestamp=&quot;</span> + timestamp + <span class=\"hljs-string\">&quot;, offset=&quot;</span> + offset.getOffset() +\n        <span class=\"hljs-string\">&quot;, offsetTimestamp=&quot;</span> + offset.getTimestamp()\n      )\n    )\n);\n\n<span class=\"hljs-comment\">// 方便地获取一个分区的偏移</span>\nconsumer.offsetsForTimes(topicPartition, timestamp).onSuccess(offsetAndTimestamp -&gt;\n  System.out.println(\n    <span class=\"hljs-string\">&quot;Offset for topic=&quot;</span> + topicPartition.getTopic() +\n    <span class=\"hljs-string\">&quot;, partition=&quot;</span> + topicPartition.getPartition() + <span class=\"hljs-string\">&quot;\\n&quot;</span> +\n    <span class=\"hljs-string\">&quot;, timestamp=&quot;</span> + timestamp + <span class=\"hljs-string\">&quot;, offset=&quot;</span> + offsetAndTimestamp.getOffset() +\n    <span class=\"hljs-string\">&quot;, offsetTimestamp=&quot;</span> + offsetAndTimestamp.getTimestamp()\n  )\n);</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_message_flow_control\"><a class=\"anchor\" href=\"#_message_flow_control\"></a>消息流控制</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>kafka 的消费者可以控制消息的流入，并且暂停 / 重启从一个主题中读取消息的操作。当消费者需要\n更多时间去处理当前消息时，它可以暂停消息流，它也可以重启消息流\n去继续处理消息。</p>\n</div>\n<div class=\"paragraph\">\n<p>为了这么做，您可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#pause--\">pause</a></code> 方法和\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#resume--\">resume</a></code> 方法。</p>\n</div>\n<div class=\"paragraph\">\n<p>在对特定的主题分区调用了暂停和重启方法后，消息处理器有可能仍然会从\n已经暂停了的主题分区接收消息，即使是在 <code>pause()</code> 方法的完成回调\n<em>已经被调用之后</em> 。 如果您使用了批处理器，一旦您调用\n<code>pause()</code> 方法的完成回调被调用， 消费者就只能从未被暂停的主题分区\n接收消息。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// 注册消息处理器</span>\nconsumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;key=&quot;</span> + record.key() + <span class=\"hljs-string\">&quot;,value=&quot;</span> + record.value() +\n    <span class=\"hljs-string\">&quot;,partition=&quot;</span> + record.partition() + <span class=\"hljs-string\">&quot;,offset=&quot;</span> + record.offset());\n\n  <span class=\"hljs-comment\">// 在接收消息的偏移到达 5 之后暂停 / 重启分区 0 的消息流</span>\n  <span class=\"hljs-keyword\">if</span> ((record.partition() == <span class=\"hljs-number\">0</span>) &amp;&amp; (record.offset() == <span class=\"hljs-number\">5</span>)) {\n\n    <span class=\"hljs-comment\">// pause the read operations</span>\n    consumer.pause(topicPartition)\n      .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Paused&quot;</span>))\n      .onSuccess(v -&gt; vertx.setTimer(<span class=\"hljs-number\">5000</span>, timeId -&gt;\n        <span class=\"hljs-comment\">// 重启读操作</span>\n        consumer.resume(topicPartition)\n      ));\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_closing_a_consumer\"><a class=\"anchor\" href=\"#_closing_a_consumer\"></a>关闭消费者</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>调用 close 方法来关闭消费者。 关闭消费者会关闭其所持有的所有连接并释放它所有的消费者资源。</p>\n</div>\n<div class=\"paragraph\">\n<p>close 方法是异步的并且在方法返回时可能还未完成。 如果您想在关闭完成后\n收到通知，那么可以向其传递一个回调处理器。</p>\n</div>\n<div class=\"paragraph\">\n<p>该回调处理器会在关闭操作完全完成后被调用。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer\n  .close()\n  .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Consumer is now closed&quot;</span>))\n  .onFailure(cause -&gt; System.out.println(<span class=\"hljs-string\">&quot;Close failed: &quot;</span> + cause));</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_sending_messages_to_a_topic\"><a class=\"anchor\" href=\"#_sending_messages_to_a_topic\"></a>向主题发送消息</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>您可以使用 <code><a href=\"../../apidocs/io/vertx/core/streams/WriteStream.html#write-java.lang.Object-\">write</a></code> 方法去发送消息 (记录) 给主题。</p>\n</div>\n<div class=\"paragraph\">\n<p>最简单的发送消息的方法是指定目标主题和相对应的值， 忽略它的键\n和分区，这种情况下消息会以轮流循环的方式呗发送给该主题的所有分区。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) {\n\n  <span class=\"hljs-comment\">// 只设置主题和消息内容的情况下，消息会被循环轮流发送给目的主题的所有分区</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">&quot;test&quot;</span>, <span class=\"hljs-string\">&quot;message_&quot;</span> + i);\n\n  producer.write(record);\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>在发送消息成功时，您可以接收到该消息在 kafka 中的元数据，例如它的主题，目标分区和它在存储中的偏移。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) {\n\n  <span class=\"hljs-comment\">// 只设置主题和消息内容的情况下，消息会被循环轮流发送给目的主题的所有分区</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">&quot;test&quot;</span>, <span class=\"hljs-string\">&quot;message_&quot;</span> + i);\n\n  producer.send(record).onSuccess(recordMetadata -&gt;\n    System.out.println(\n      <span class=\"hljs-string\">&quot;Message &quot;</span> + record.value() + <span class=\"hljs-string\">&quot; written on topic=&quot;</span> + recordMetadata.getTopic() +\n      <span class=\"hljs-string\">&quot;, partition=&quot;</span> + recordMetadata.getPartition() +\n      <span class=\"hljs-string\">&quot;, offset=&quot;</span> + recordMetadata.getOffset()\n    )\n  );\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>当您需要指定消息发送的分区时，您需要指定它的分区标识符或\n消息的键。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">10</span>; i++) {\n\n  <span class=\"hljs-comment\">// 指定分区</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">&quot;test&quot;</span>, <span class=\"hljs-keyword\">null</span>, <span class=\"hljs-string\">&quot;message_&quot;</span> + i, <span class=\"hljs-number\">0</span>);\n\n  producer.write(record);\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>由于消息的生产者使用键的哈希计算对应的主题分区，您可以利用这一点保证拥有相同键的所有\n消息都按照顺序被发送给一个相同的分区。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">10</span>; i++) {\n\n  <span class=\"hljs-comment\">// 根据奇偶性设置消息的键</span>\n  <span class=\"hljs-keyword\">int</span> key = i % <span class=\"hljs-number\">2</span>;\n\n  <span class=\"hljs-comment\">// 指定一个消息的键，所有键相同的消息会被发给同一个分区</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">&quot;test&quot;</span>, String.valueOf(key), <span class=\"hljs-string\">&quot;message_&quot;</span> + i);\n\n  producer.write(record);\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>请记住：可共用的生产者通过 <code>createShared</code> 方法的第一次调用创建，并且它的配置在此时被设置，\n可共用的生产者使用时必须确保配置相同。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_sharing_a_producer\"><a class=\"anchor\" href=\"#_sharing_a_producer\"></a>公用生产者</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>有时您需要在多个 verticle 或上下文（context）中共享同一个生产者。</p>\n</div>\n<div class=\"paragraph\">\n<p>使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#createShared-io.vertx.core.Vertx-java.lang.String-java.util.Map-\">KafkaProducer.createShared</a></code> 方法\n返回一个可以被安全地共用的 producer。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">KafkaProducer&lt;String, String&gt; producer1 = KafkaProducer.createShared(vertx, <span class=\"hljs-string\">&quot;the-producer&quot;</span>, config);\n\n<span class=\"hljs-comment\">// 之后您可以关闭它</span>\nproducer1.close();</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>通过该方法返回的生产者会共享相同的资源（线程，连接） 。</p>\n</div>\n<div class=\"paragraph\">\n<p>当您使用完毕该生产者后，可以简单地关闭它。 当所有共用的生产者被关闭后，所有的资源\n也会被释放。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_closing_a_producer\"><a class=\"anchor\" href=\"#_closing_a_producer\"></a>关闭生产者</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>调用 close 方法来关闭生产者。关闭生产者会关闭其打开的连接并释放其所占有的所有资源。</p>\n</div>\n<div class=\"paragraph\">\n<p>关闭是异步进行的，因此在调用返回时生产者可能还没有完全关闭。 如果您想在\n关闭完成时收到通知，那么您可以传入一个回调。</p>\n</div>\n<div class=\"paragraph\">\n<p>这个回调会在生产者被完全关闭后调用。</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">producer\n  .close()\n  .onSuccess(v -&gt; System.out.println(<span class=\"hljs-string\">&quot;Producer is now closed&quot;</span>))\n  .onFailure(cause -&gt; System.out.println(<span class=\"hljs-string\">&quot;Close failed: &quot;</span> + cause));</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_getting_topic_partition_information_2\"><a class=\"anchor\" href=\"#_getting_topic_partition_information_2\"></a>获取主题分片信息</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>您可以调用 <code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#partitionsFor-java.lang.String-io.vertx.core.Handler-\">partitionsFor</a></code> 方法来获取\n指定主题的分片信息：</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">producer\n  .partitionsFor(<span class=\"hljs-string\">&quot;test&quot;</span>)\n  .onSuccess(partitions -&gt;\n    partitions.forEach(System.out::println)\n  );</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_handling_errors\"><a class=\"anchor\" href=\"#_handling_errors\"></a>处理错误</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>kafka 客户端（消费者或生产者）和 kafka 集群间的异常处理 (例如连接超时) 需要用到\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#exceptionHandler-io.vertx.core.Handler-\">exceptionHandler</a></code> 方法或\n<code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#exceptionHandler-io.vertx.core.Handler-\">exceptionHandler</a></code> 方法</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.exceptionHandler(e -&gt; {\n  System.out.println(<span class=\"hljs-string\">&quot;Error = &quot;</span> + e.getMessage());\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_automatic_clean_up_in_verticles\"><a class=\"anchor\" href=\"#_automatic_clean_up_in_verticles\"></a>verticle 的自动清理</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>如果您是在 verticle 中创建 kafka 的消费者和生产者的，那么这些消费者和生产者会在\n该 verticle 被取消部署时被自动清理。</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_vert_x_serializersdeserializers\"><a class=\"anchor\" href=\"#_using_vert_x_serializersdeserializers\"></a>使用 Vert.x 的序列化器 / 反序列化器</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Vert.x 的 Kafka 客户端的实现自带了对 Buffer 数据类型， json 对象\n和 json 对象数组的序列化器和反序列化器的包装。</p>\n</div>\n<div class=\"paragraph\">\n<p>使用消费者时您可以直接接收 Buffer 数据类型</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.BufferDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.BufferDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;group.id&quot;</span>, <span class=\"hljs-string\">&quot;my_group&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;auto.offset.reset&quot;</span>, <span class=\"hljs-string\">&quot;earliest&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;enable.auto.commit&quot;</span>, <span class=\"hljs-string\">&quot;false&quot;</span>);\n\n<span class=\"hljs-comment\">// 创建一个可以反序列化 json 对象的消费者</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonObjectDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonObjectDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;group.id&quot;</span>, <span class=\"hljs-string\">&quot;my_group&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;auto.offset.reset&quot;</span>, <span class=\"hljs-string\">&quot;earliest&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;enable.auto.commit&quot;</span>, <span class=\"hljs-string\">&quot;false&quot;</span>);\n\n<span class=\"hljs-comment\">// 创建一个可以反序列化 json 对象数组的消费者</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonArrayDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.deserializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonArrayDeserializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;group.id&quot;</span>, <span class=\"hljs-string\">&quot;my_group&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;auto.offset.reset&quot;</span>, <span class=\"hljs-string\">&quot;earliest&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;enable.auto.commit&quot;</span>, <span class=\"hljs-string\">&quot;false&quot;</span>);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>在生产者端，您也可以这么做</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.serializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.BufferSerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.serializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.BufferSerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;acks&quot;</span>, <span class=\"hljs-string\">&quot;1&quot;</span>);\n\n<span class=\"hljs-comment\">// 创建一个可以序列化 json 对象的生产者</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.serializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonObjectSerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.serializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonObjectSerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;acks&quot;</span>, <span class=\"hljs-string\">&quot;1&quot;</span>);\n\n<span class=\"hljs-comment\">// 创建一个可以序列化 json 对象数组的生产者</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;key.serializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonArraySerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;value.serializer&quot;</span>, <span class=\"hljs-string\">&quot;io.vertx.kafka.client.serialization.JsonArraySerializer&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;acks&quot;</span>, <span class=\"hljs-string\">&quot;1&quot;</span>);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>您可以在创建时直接指定序列化器/反序列化器：</p>\n</div>\n<div class=\"paragraph\">\n<p>对于消费者</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;group.id&quot;</span>, <span class=\"hljs-string\">&quot;my_group&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;auto.offset.reset&quot;</span>, <span class=\"hljs-string\">&quot;earliest&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;enable.auto.commit&quot;</span>, <span class=\"hljs-string\">&quot;false&quot;</span>);\n\n<span class=\"hljs-comment\">// 创建一个可以反序列化 Buffer 数据类型的消费者</span>\nKafkaConsumer&lt;Buffer, Buffer&gt; bufferConsumer = KafkaConsumer.create(vertx, config, Buffer.class, Buffer.class);\n\n<span class=\"hljs-comment\">// 创建一个可以反序列化 json 对象的消费者</span>\nKafkaConsumer&lt;JsonObject, JsonObject&gt; jsonObjectConsumer = KafkaConsumer.create(vertx, config, JsonObject.class, JsonObject.class);\n\n<span class=\"hljs-comment\">// 创建一个可以反序列化 json 对象数组的消费者</span>\nKafkaConsumer&lt;JsonArray, JsonArray&gt; jsonArrayConsumer = KafkaConsumer.create(vertx, config, JsonArray.class, JsonArray.class);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>而对于生产者</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">&quot;bootstrap.servers&quot;</span>, <span class=\"hljs-string\">&quot;localhost:9092&quot;</span>);\nconfig.put(<span class=\"hljs-string\">&quot;acks&quot;</span>, <span class=\"hljs-string\">&quot;1&quot;</span>);\n\n<span class=\"hljs-comment\">// 创建一个可以序列化 Buffer 数据类型的生产者</span>\nKafkaProducer&lt;Buffer, Buffer&gt; bufferProducer = KafkaProducer.create(vertx, config, Buffer.class, Buffer.class);\n\n<span class=\"hljs-comment\">// 创建一个可以序列化 json 对象的生产者</span>\nKafkaProducer&lt;JsonObject, JsonObject&gt; jsonObjectProducer = KafkaProducer.create(vertx, config, JsonObject.class, JsonObject.class);\n\n<span class=\"hljs-comment\">// 创建一个可以序列化 json 对象数组的生产者</span>\nKafkaProducer&lt;JsonArray, JsonArray&gt; jsonArrayProducer = KafkaProducer.create(vertx, config, JsonArray.class, JsonArray.class);</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_rxjava_3_api\"><a class=\"anchor\" href=\"#_rxjava_3_api\"></a>RxJava 3 接口</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Kafka 客户端提供了在原有 API 基础上的响应式接口</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Observable&lt;KafkaConsumerRecord&lt;String, Long&gt;&gt; observable = consumer.toObservable();\n\nobservable\n  .map(record -&gt; record.value())\n  .buffer(<span class=\"hljs-number\">256</span>)\n  .map(\n  list -&gt; list.stream().mapToDouble(n -&gt; n).average()\n).subscribe(val -&gt; {\n\n  <span class=\"hljs-comment\">// 获取平均值</span>\n\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_automatic_trace_propagation\"><a class=\"anchor\" href=\"#_automatic_trace_propagation\"></a>自动追踪传播</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>当您配置 Vert.x 开启追踪时 (参见 <code><a href=\"../../apidocs/io/vertx/core/VertxOptions.html#setTracingOptions-io.vertx.core.tracing.TracingOptions-\">setTracingOptions</a></code>)，\n追踪可以通过 Kafka 的消息自动传播。</p>\n</div>\n<div class=\"paragraph\">\n<p>Kafka 的生产者会在写入消息时自动添加一个 Span 去追踪，追踪的上下文通过\nKafka 消息头部传递。并且消费者会在收到消息后根据消息头部信息重建 Span。</p>\n</div>\n<div class=\"paragraph\">\n<p>参考以下信息\n<a href=\"https://github.com/opentracing/specification/blob/master/semantic_conventions.md\">OpenTracing semantic convention</a>,\nSpan 的标签包括：</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>span.kind</code>，类型是 <code>consumer</code> 或 <code>producer</code></p>\n</li>\n<li>\n<p><code>peer.address</code> 可以使用 <code><a href=\"../../apidocs/io/vertx/kafka/client/common/KafkaClientOptions.html#setTracePeerAddress-java.lang.String-\">setTracePeerAddress</a></code> 配置。如果没有设置，那么会使用配置中的 Kafka 服务器地址</p>\n</li>\n<li>\n<p><code>peer.hostname</code> 通过解析 <code>peer.address</code> 得到</p>\n</li>\n<li>\n<p><code>peer.port</code> 通过解析 <code>peer.address</code> 得到</p>\n</li>\n<li>\n<p><code>peer.service</code> 一直是 always <code>kafka</code></p>\n</li>\n<li>\n<p><code>message_bus.destination</code>, 会设置为 kafka 消息的主题</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Unresolved directive in index.adoc - include::admin.adoc[]</p>\n</div>\n</div>\n</div>","version":"4.1.3"},"__N_SSG":true}