{"pageProps":{"categories":["releases","guides","news"],"post":{"meta":{"title":"Centralized logging for Vert.x applications using the ELK stack","category":"guides","authors":[{"name":"Ricardo Hernandez","github_id":"ricardohmon"}],"summary":"This post entry describes a solution to achieve centralized logging of Vert.x applications using the ELK stack (Logstash, Elasticsearch, and Kibana)."},"date":"2016-09-08","slug":"centralized-logging-for-vert-x-applications-using-the-elk-stack","readingTime":{"text":"11 min read","minutes":10.45,"time":627000,"words":2090},"content":{"compiledSource":"\"use strict\";\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar layoutProps = {};\nvar MDXLayout = \"wrapper\";\n\nfunction MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This post entry de\\xADscribes a so\\xADlu\\xADtion to achieve cen\\xADtral\\xADized log\\xADging of Vert.x ap\\xADpli\\xADca\\xADtions using the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.elastic.co/webinars/introduction-elk-stack\"\n  }), \"ELK stack\"), \", a set of tools in\\xADclud\\xADing Logstash, Elas\\xADtic\\xADsearch, and Kibana that are well known to work to\\xADgether seam\\xADlessly.\"), mdx(\"h2\", {\n    \"id\": \"preamble\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#preamble\"\n  })), \"Preamble\"), mdx(\"p\", null, \"This post was writ\\xADten in con\\xADtext of the project ti\\xADtled \\u201C\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://summerofcode.withgoogle.com/projects/#4858492141699072\"\n  }), \"De\\xADvOps tool\\xADing for Vert.x ap\\xADpli\\xADca\\xADtions\"), \"\\u201D, one of the Vert.x projects tak\\xADing place dur\\xADing the 2016 edi\\xADtion of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://summerofcode.withgoogle.com/about/\"\n  }), \"Google Sum\\xADmer of Code\"), \", a pro\\xADgram that aims to bring to\\xADgether stu\\xADdents with open source or\\xADga\\xADni\\xADza\\xADtions, in order to help them to gain ex\\xADpo\\xADsure to soft\\xADware de\\xADvel\\xADop\\xADment prac\\xADtices and real-\\u200Bworld chal\\xADlenges.\"), mdx(\"h2\", {\n    \"id\": \"introduction\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#introduction\"\n  })), \"Introduction\"), mdx(\"p\", null, \"Cen\\xADtral\\xADized log\\xADging is an im\\xADpor\\xADtant topic while build\\xADing a Mi\\xADcroser\\xADvices ar\\xADchi\\xADtec\\xADture and it is a step for\\xADward to adopt\\xADing the De\\xADvOps cul\\xADture. Hav\\xADing an over\\xADall so\\xADlu\\xADtion par\\xADti\\xADtioned into a set of ser\\xADvices dis\\xADtrib\\xADuted across the In\\xADter\\xADnet can rep\\xADre\\xADsent a chal\\xADlenge when try\\xADing to mon\\xADi\\xADtor the log out\\xADput of each of them, hence, a tool that helps to ac\\xADcom\\xADplish this re\\xADsults very help\\xADful.\"), mdx(\"h2\", {\n    \"id\": \"overview\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#overview\"\n  })), \"Overview\"), mdx(\"p\", null, \"As shown in the di\\xADa\\xADgram below, the gen\\xADeral cen\\xADtral\\xADized log\\xADging so\\xADlu\\xADtion com\\xADprises two main el\\xADe\\xADments: the ap\\xADpli\\xADca\\xADtion server, which runs our Vert.x ap\\xADpli\\xADca\\xADtion; and a sep\\xADa\\xADrate server, host\\xADing the ELK stack. Both el\\xADe\\xADments are linked by File\\xADbeat, a highly con\\xADfig\\xADurable tool ca\\xADpa\\xADble of ship\\xADping our ap\\xADpli\\xADca\\xADtion logs to the Logstash in\\xADstance, i.e., our gate\\xADway to the ELK stack.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/images/blog/centralized-logging-using-elk/elk-overview.svg\",\n    \"alt\": \"Overview of centralized logging with ELK\"\n  }))), mdx(\"h2\", {\n    \"id\": \"app-logging-configuration\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#app-logging-configuration\"\n  })), \"App logging configuration\"), mdx(\"p\", null, \"The ap\\xADproach de\\xADscribed here is based on a File\\xADbeat + Logstash con\\xADfig\\xADu\\xADra\\xADtion, that means first we need to make sure our app logs to a file, whose records will be shipped to Logstash by File\\xADbeat. Luck\\xADily, Vert.x pro\\xADvides the means to \", mdx(Link, {\n    href: \"/docs/vertx-core/java/#_logging\",\n    passHref: true,\n    mdxType: \"Link\"\n  }, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"\"\n  }), \"con\\xADfig\\xADure\")), \" al\\xADter\\xADna\\xADtive log\\xADging frame\\xADworks (e.g., Log4j, Log4j2 and SLF4J) be\\xADsides the de\\xADfault JUL log\\xADging. How\\xADever, we can use File\\xADbeat in\\xADde\\xADpen\\xADdently of the log\\xADging frame\\xADwork cho\\xADsen.\"), mdx(\"h3\", {\n    \"id\": \"log4j-logging\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#log4j-logging\"\n  })), \"Log4j Logging\"), mdx(\"p\", null, \"The demo that ac\\xADcom\\xADpa\\xADnies this post re\\xADlies on Log4j2 as the log\\xADging frame\\xADwork. We in\\xADstructed Vert.x to use this frame\\xADwork fol\\xADlow\\xADing the \", mdx(Link, {\n    href: \"/docs/vertx-core/java/#_logging\",\n    passHref: true,\n    mdxType: \"Link\"\n  }, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"\"\n  }), \"guide\\xADlines\")), \" and we made sure our log\\xADging calls are made asyn\\xADchro\\xADnous, since we don\\u2019t want them to block our ap\\xADpli\\xADca\\xADtion. For this pur\\xADpose, we opted for the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"AsyncAppender\"), \" and this was in\\xADcluded in the Log4J con\\xADfig\\xADu\\xADra\\xADtion to\\xADgether with the log out\\xADput for\\xADmat de\\xADscribed in a XML con\\xADfig\\xADu\\xADra\\xADtion avail\\xADable in the ap\\xADpli\\xADca\\xADtion\\u2019s \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Re\\xADsource\"), \" folder.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-xml\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Configuration\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Appenders\"), \">\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"RollingFile\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"name\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_logs\\\"\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"append\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"true\\\"\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"fileName\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/var/log/vertx.log\\\"\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"filePattern\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/var/log/vertx/$${date:yyyy-MM}/vertx-%d{MM-dd-yyyy}-%i.log.gz\\\"\"), \">\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"PatternLayout\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"pattern\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%d{ISO8601} %-5p %c:%L - %m%n\\\"\"), \" />\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"RollingFile\"), \">\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Async\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"name\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_async\\\"\"), \">\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"AppenderRef\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"ref\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_logs\\\"\"), \"/>\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Async\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Appenders\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Loggers\"), \">\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Root\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"level\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"DEBUG\\\"\"), \">\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"<\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"AppenderRef\"), \" \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"ref\"), \"=\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"vertx_async\\\"\"), \" />\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Root\"), \">\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Loggers\"), \">\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-tag\"\n  }), \"</\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-name\"\n  }), \"Configuration\"), \">\"), \"\\n\")), mdx(\"h3\", {\n    \"id\": \"filebeat-configuration\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#filebeat-configuration\"\n  })), \"Filebeat configuration\"), mdx(\"p\", null, \"Now that we have con\\xADfig\\xADured the log out\\xADput of our Vert.x ap\\xADpli\\xADca\\xADtion to be stored in the file sys\\xADtem, we del\\xADe\\xADgate to File\\xADbeat the task of for\\xADward\\xADing the logs to the Logstash in\\xADstance. File\\xADbeat can be con\\xADfig\\xADured through a YAML file con\\xADtain\\xADing the logs out\\xADput lo\\xADca\\xADtion and the pat\\xADtern to in\\xADter\\xADpret mul\\xADti\\xADline logs (i.e., stack traces). Also, the Logstash out\\xADput plug\\xADin is con\\xADfig\\xADured with the host lo\\xADca\\xADtion and a se\\xADcure con\\xADnec\\xADtion is en\\xADforced using the cer\\xADtifi\\xADcate from the ma\\xADchine host\\xADing Logstash. We set the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"document_type\"), \" to the type of in\\xADstance that this log be\\xADlongs to, which could later help us while in\\xADdex\\xADing our logs in\\xADside Elas\\xADtic\\xADsearch.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-yaml\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"filebeat:\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"prospectors:\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"document_type:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"trader_dashboard\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"paths:\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"/var/log/vertx.log\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"multiline:\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"pattern:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"^[0-9]+\\\"\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"negate:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"match:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"after\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"output:\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"logstash:\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"enabled:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"hosts:\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"elk:5044\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"timeout:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"15\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"tls:\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"insecure:\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"false\"), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"certificate_authoritites:\"), \"\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-bullet\"\n  }), \"-\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"/etc/pki/tls/certs/logstash-beats.crt\"), \"\\n\")), mdx(\"h2\", {\n    \"id\": \"elk-configuration\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#elk-configuration\"\n  })), \"ELK configuration\"), mdx(\"p\", null, \"To take fully ad\\xADvan\\xADtage of the ELK stack with re\\xADspect to Vert.x and our app logs, we need to con\\xADfig\\xADure each of its in\\xADdi\\xADvid\\xADual com\\xADpo\\xADnents, namely Logstash, Elas\\xADtic\\xADsearch and Kibana.\"), mdx(\"h3\", {\n    \"id\": \"logstash\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#logstash\"\n  })), \"Logstash\"), mdx(\"p\", null, \"Logstash is the com\\xADpo\\xADnent within the ELK stack that is in charge of ag\\xADgre\\xADgat\\xADing the logs from each of the sources and for\\xADward\\xADing them to the Elas\\xADtic\\xADsearch in\\xADstance.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Con\\xADfig\\xADur\\xADing Logstash is straight\\xADfor\\xADward with the help of the spe\\xADcific input and out\\xADput plu\\xADg\\xADins for Beats and Elas\\xADtic\\xADsearch, re\\xADspec\\xADtively.\\nIn the pre\\xADvi\\xADous sec\\xADtion we men\\xADtioned that File\\xADbeat could be eas\\xADily cou\\xADpled with Logstash. Now, we see that this can be done by just spec\\xADi\\xADfy\\xADing \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Beat\"), \" as the input plug\\xADin and set the pa\\xADra\\xADme\\xADters needed to be reached by our ship\\xADpers (lis\\xADten\\xADing port, ssl key and cer\\xADtifi\\xADcate lo\\xADca\\xADtion).\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-bash\"\n  }), \"input {\\n  beats {\\n    port => 5044\\n    ssl => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \"\\n    ssl_certificate => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/etc/pki/tls/certs/logstash-beats.crt\\\"\"), \"\\n    ssl_key => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/etc/pki/tls/private/logstash-beats.key\\\"\"), \"\\n  }\\n}\\n\")), mdx(\"p\", null, \"Now that we are ready to re\\xADceive logs from the app, we can use Logstash fil\\xADter\\xADing ca\\xADpa\\xADbil\\xADi\\xADties to spec\\xADify the for\\xADmat of our logs and ex\\xADtract the fields so they can be in\\xADdexed more ef\\xADfi\\xADciently by Elas\\xADtic\\xADsearch.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"grok\"), \" fil\\xADter\\xADing plug\\xADin comes handy in this sit\\xADu\\xADa\\xADtion. This plug\\xADin al\\xADlows to de\\xADclare the logs for\\xADmat using pre\\xADde\\xADfined and cus\\xADtomized pat\\xADterns based in reg\\xADu\\xADlar ex\\xADpres\\xADsions al\\xADlow\\xADing to de\\xADclare new fields from the in\\xADfor\\xADma\\xADtion ex\\xADtracted from each log line. In the fol\\xADlow\\xADing block, we in\\xADstruct Logstash to rec\\xADog\\xADnize our Log4j pat\\xADtern in\\xADside a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"message\"), \" field, which con\\xADtains the log mes\\xADsage shipped by File\\xADbeat. After that, the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"date\"), \" fil\\xADter\\xADing plug\\xADin parses the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"timestamp\"), \" field ex\\xADtracted in the pre\\xADvi\\xADous step and re\\xADplaces it for the one set by File\\xADbeat after read\\xADing the log out\\xADput file.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-bash\"\n  }), \"filter {\\n  grok {\\n    break_on_match => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"false\"), \"\\n    match =>  [ \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"message\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%{LOG4J}\\\"\"), \"]\\n  }\\n  date{\\n    match => [ \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"timestamp_string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"ISO8601\\\"\"), \"]\\n    remove_field => [ \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"timestamp_string\\\"\"), \" ]\\n  }\\n}\\n\")), mdx(\"p\", null, \"The Log4j pat\\xADtern is not in\\xADcluded within the Logstash con\\xADfig\\xADu\\xADra\\xADtion, how\\xADever, we can spec\\xADify it using pre\\xADde\\xADfined data for\\xADmats shipped with Logstash and adapt it to the spe\\xADcific log for\\xADmats re\\xADquired in our ap\\xADpli\\xADca\\xADtion, as shown next.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-ruby\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-comment\"\n  }), \"# Pattern to match our Log4j format\"), \"\\nSPACING (?\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-symbol\"\n  }), \":\"), \"[\\\\s]+)\\nLOGGER (?\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-symbol\"\n  }), \":\"), \"[a-zA-Z$_][a-zA-Z$_0-\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"9\"), \"]*\\\\.)*[a-zA-Z$_][a-zA-Z$_0-\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"9\"), \"]*\\nLINE \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{INT}\"), \"?\\nLOG4J \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{TIMESTAMP_ISO8601:timestamp_string}\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{LOGLEVEL:log_level}\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{SPACING}\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{LOGGER:logger_name}\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-symbol\"\n  }), \":\", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{LINE:loc_line}\")), \" - \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"%{JAVALOGMESSAGE:log_message}\"), \"\\n\")), mdx(\"p\", null, \"Fi\\xADnally, we take a look at Logstash\\u2019s out\\xADput con\\xADfig\\xADu\\xADra\\xADtion. This sim\\xADply points to our elas\\xADtic\\xADsearch in\\xADstance, in\\xADstructs it to pro\\xADvide a list of all clus\\xADter nodes (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sniffing\"), \"), de\\xADfines the name pat\\xADtern for our in\\xADdices, as\\xADsigns the doc\\xADu\\xADment type ac\\xADcord\\xADing to the meta\\xADdata com\\xADing from File\\xADbeat, and al\\xADlows to de\\xADfine a cus\\xADtom index tem\\xADplate for our data.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-puppet\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"output\"), \" {\\n  elasticsearch {\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"hosts\"), \" => [\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"localhost\\\"\"), \"]\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"sniffing\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"true\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"manage_template\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"true\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"index\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%{[@metadata][beat]}-%{+YYYY.MM.dd}\\\"\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"document_type\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"%{[@metadata][type]}\\\"\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"template\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"/etc/filebeat/vertx_app_filebeat.json\\\"\"), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"template_overwrite\"), \" => \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-keyword\"\n  }), \"true\"), \"\\n  }\\n}\\n\")), mdx(\"h3\", {\n    \"id\": \"elasticsearch\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#elasticsearch\"\n  })), \"Elasticsearch\"), mdx(\"p\", null, \"Elas\\xADtic\\xADsearch is the cen\\xADtral com\\xADpo\\xADnent that en\\xADables the ef\\xADfi\\xADcient in\\xADdex\\xADing and real-\\u200Btime search ca\\xADpa\\xADbil\\xADi\\xADties of the stack. To take the most ad\\xADvan\\xADtage of Elas\\xADtic\\xADsearch, we can pro\\xADvide an in\\xADdex\\xADing tem\\xADplate of our in\\xADcom\\xADing logs, which can help to op\\xADti\\xADmize the data stor\\xADage and match the queries is\\xADsued by Kibana at a later point.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"In the ex\\xADam\\xADple below, we see an index tem\\xADplate that would be ap\\xADplied to any index match\\xADing the pat\\xADtern \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"filebeat-*\"), \". Ad\\xADdi\\xADtion\\xADally, we de\\xADclare our new log fields \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"type\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"host\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"log_level\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"logger_name\"), \", and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"log_message\"), \", which are set as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"not_analyzed\"), \" ex\\xADcept for the last two that are set as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"analyzed\"), \" al\\xADlow\\xADing to per\\xADform queries based on reg\\xADu\\xADlar ex\\xADpres\\xADsions and not re\\xADstricted to query the full text.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-json\"\n  }), \"{\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"mappings\\\"\"), \": {\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"_default_\\\"\"), \": {\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"_all\\\"\"), \": {\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"enabled\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \",\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"norms\\\"\"), \": {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"enabled\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"false\"), \"\\n        }\\n      },\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"dynamic_templates\\\"\"), \": [\\n        {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"template1\\\"\"), \": {\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"mapping\\\"\"), \": {\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"doc_values\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-literal\"\n  }), \"true\"), \",\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"ignore_above\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-number\"\n  }), \"1024\"), \",\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \",\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"{dynamic_type}\\\"\"), \"\\n            },\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"match\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"*\\\"\"), \"\\n          }\\n        }\\n      ],\\n      \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"properties\\\"\"), \": {\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"@timestamp\\\"\"), \": {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"date\\\"\"), \"\\n        },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"offset\\\"\"), \": {\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"long\\\"\"), \",\\n          \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"doc_values\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"true\\\"\"), \"\\n        },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"host\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"log_level\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"not_analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"logger_name\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"analyzed\\\"\"), \" },\\n        \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"log_message\\\"\"), \": { \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"type\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"string\\\"\"), \", \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"analyzed\\\"\"), \" }\\n      }\\n    }\\n  },\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"settings\\\"\"), \": {\\n    \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"index.refresh_interval\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"5s\\\"\"), \"\\n  },\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attr\"\n  }), \"\\\"template\\\"\"), \": \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-string\"\n  }), \"\\\"filebeat-*\\\"\"), \"\\n}\\n\")), mdx(\"h3\", {\n    \"id\": \"kibana\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#kibana\"\n  })), \"Kibana\"), mdx(\"p\", null, \"Al\\xADthough we could fetch all our logs from Elas\\xADtic\\xADsearch through its API, Kibana is a pow\\xADer\\xADful tool that al\\xADlows a more friendly query and vi\\xADsu\\xADal\\xADiza\\xADtion.\\nBe\\xADsides the op\\xADtion to query our data through the avail\\xADable in\\xADdexed field names and search boxes al\\xADlow\\xADing typ\\xADing spe\\xADcific queries, Kibana al\\xADlows cre\\xADat\\xADing our own \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Vi\\xADsu\\xADal\\xADiza\\xADtions\"), \" and \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Dash\\xADboards\"), \". Com\\xADbined, they rep\\xADre\\xADsent a pow\\xADer\\xADful way to dis\\xADplay data and gain in\\xADsight in a cus\\xADtomized man\\xADner.\\nThe ac\\xADcom\\xADpa\\xADnied demo ships with a cou\\xADple of sam\\xADple dash\\xADboards and vi\\xADsu\\xADal\\xADiza\\xADtions that take ad\\xADvan\\xADtage of the log fields that we spec\\xADi\\xADfied in our index tem\\xADplate and throw valu\\xADable in\\xADsight. This in\\xADcludes: vi\\xADsu\\xADal\\xADiz\\xADing the num\\xADber of log mes\\xADsages re\\xADceived by ELK, ob\\xADserve the pro\\xADpor\\xADtion of mes\\xADsages that each log source pro\\xADduces, and di\\xADrectly find out the sources of error logs.\"), mdx(\"p\", null, mdx(\"img\", _extends({\n    parentName: \"p\"\n  }, {\n    \"src\": \"/images/blog/centralized-logging-using-elk/kibana-dashboard.png\",\n    \"alt\": \"Kibana Dashboard\\\" width=\\\"550\"\n  }))), mdx(\"h2\", {\n    \"id\": \"log-shipping-challenge\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#log-shipping-challenge\"\n  })), \"Log shipping challenge\"), mdx(\"p\", null, \"The so\\xADlu\\xADtion pre\\xADsented here re\\xADlied on File\\xADbeat to ship log data to Logstash. How\\xADever, if you are fa\\xADmil\\xADiar with the Log4j frame\\xADwork you may be aware that there ex\\xADists a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Sock\\xADe\\xADtAp\\xADpen\\xADder\"), \" that al\\xADlows to write log events di\\xADrectly to a re\\xADmote server using a TCP con\\xADnec\\xADtion. Al\\xADthough in\\xADclud\\xADing the File\\xADbeat + Logstash com\\xADbi\\xADna\\xADtion  may sound an un\\xADnec\\xADes\\xADsary over\\xADhead to the log\\xADging pipeline, they pro\\xADvide a num\\xADber of ben\\xADe\\xADfits in com\\xADpar\\xADi\\xADson to the Log4j socket al\\xADter\\xADna\\xADtive:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The Sock\\xADe\\xADtAp\\xADpen\\xADder re\\xADlies on the spe\\xADcific se\\xADri\\xADal\\xADiza\\xADtion of Log4j\\u2019s \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"Lo\\xADgEvent\"), \" ob\\xADjects, which is no an in\\xADter\\xADchange\\xADable for\\xADmat as JSON, which is used by the Beats so\\xADlu\\xADtion. Al\\xADthough there are \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/majikthys/log4j2-logstash-jsonevent-layout\"\n  }), \"at\\xADtempts\"), \" to out\\xADput the logs in a JSON for\\xADmat for Logstash, it doesn\\u2019t sup\\xADport mul\\xADti\\xADline logs, which re\\xADsults in mes\\xADsages being split into dif\\xADfer\\xADent events by Logstash. On the other hand, there is no of\\xADfi\\xADcial nor sta\\xADble \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://www.elastic.co/guide/en/logstash/current/input-plugins.html\"\n  }), \"input plugin\"), \" for Log4j ver\\xADsion 2.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"While en\\xADabling Log4j\\u2019s async log\\xADging mode in an ap\\xADpli\\xADca\\xADtion del\\xADe\\xADgates log\\xADging op\\xADer\\xADa\\xADtions to sep\\xADa\\xADrate threads, given their co\\xADex\\xADis\\xADtence in the same JVM there is still the risk of data loss in case of a sud\\xADden JVM ter\\xADmi\\xADna\\xADtion with\\xADout proper log chan\\xADnel clos\\xADing.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"File\\xADbeat is a data ship\\xADper de\\xADsigned to deal with many con\\xADstraints that arise in dis\\xADtrib\\xADuted en\\xADvi\\xADron\\xADments in a re\\xADli\\xADable man\\xADner, there\\xADfore it pro\\xADvides op\\xADtions to tai\\xADlor and scale this op\\xADer\\xADa\\xADtion to our needs: the pos\\xADsi\\xADbil\\xADity to load bal\\xADance be\\xADtween mul\\xADti\\xADple Logstash in\\xADstances, spec\\xADify the num\\xADber of si\\xADmul\\xADta\\xADne\\xADous File\\xADbeat work\\xADers that ship log files, and spec\\xADify a com\\xADpres\\xADsion level in order to re\\xADduce the con\\xADsumed band\\xADwidth. Be\\xADsides that, logs can be shipped in spe\\xADcific batch sizes, with max\\xADi\\xADmum amount of re\\xADtries, and spec\\xADi\\xADfy\\xADing a con\\xADnec\\xADtion time\\xADout.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Lastly, al\\xADthough File\\xADbeat can for\\xADward logs di\\xADrectly to Elas\\xADtic\\xADsearch, using Logstash as an in\\xADter\\xADme\\xADdi\\xADary of\\xADfers the pos\\xADsi\\xADbil\\xADity to col\\xADlect logs from di\\xADverse sources (e.g., sys\\xADtem met\\xADrics).\")), mdx(\"h2\", {\n    \"id\": \"demo\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#demo\"\n  })), \"Demo\"), mdx(\"p\", null, \"This post is ac\\xADcom\\xADpa\\xADnied by a demo based on the Vert.x Mi\\xADcroser\\xADvices \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://vertx-lab.dynamis-technologies.com/\"\n  }), \"work\\xADshop\"), \", where each of them is shipped in a Docker con\\xADtainer sim\\xADu\\xADlat\\xADing a dis\\xADtrib\\xADuted sys\\xADtem com\\xADposed of in\\xADde\\xADpen\\xADdent ad\\xADdress\\xADable nodes.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Also, the ELK stack is pro\\xADvi\\xADsioned using a pre\\xADcon\\xADfig\\xADured Docker image by \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/spujadas\"\n  }), \"S\\xE9bastien Pu\\xADjadas\"), \".\"), mdx(\"p\", null, \"Fol\\xADlow\\xADing the guide\\xADlines in this post, this demo con\\xADfig\\xADures each of the Mi\\xADcroser\\xADvices of the work\\xADshop, sets up a File\\xADbeat process on each of them to ship the logs to a cen\\xADtral con\\xADtainer host\\xADing the ELK stack.\"), mdx(\"h3\", {\n    \"id\": \"installation\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#installation\"\n  })), \"Installation\"), mdx(\"p\", null, \"In order to run this demo, it is nec\\xADes\\xADsary to have Docker in\\xADstalled, then pro\\xADceed with:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cloning or down\\xADload\\xADing the demo \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/ricardohmon/vertx-elk\"\n  }), \"repos\\xADi\\xADtory\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sep\\xADa\\xADrately, ob\\xADtain\\xADing the source code of the \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/ricardohmon/vertx-microservices-workshop/tree/elk-demo\"\n  }), \"branch\"), \" of the Mi\\xADcroser\\xADvices work\\xADshop adapted for this demo.\")), mdx(\"h3\", {\n    \"id\": \"building-the-example\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#building-the-example\"\n  })), \"Building the example\"), mdx(\"p\", null, \"The Docker im\\xADages be\\xADlong\\xADing to the Vert.x Mi\\xADcroser\\xADvices work\\xADshop need to be built sep\\xADa\\xADrately to this project be\\xADfore this project can be launched.\"), mdx(\"h3\", {\n    \"id\": \"building-the-vertx-microservices-workshop-docker-images\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#building-the-vertx-microservices-workshop-docker-images\"\n  })), \"Building the Vert.x Microservices workshop Docker images.\"), mdx(\"p\", null, \"Build the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"root\"), \" project and the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Trader Dash\\xADboard\"), \" fol\\xADlowed by each of the mod\\xADules con\\xADtained in the so\\xADlu\\xADtion folder. Issue the fol\\xADlow\\xADing com\\xADmands for this:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-bash\"\n  }), \"mvn clean install\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" trader-dashboard\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../solution/audit-service\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../compulsive-traders\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../portfolio-service\\nmvn package docker:build\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-built_in\"\n  }), \"cd\"), \" ../quote-generator/\\nmvn package docker:build\\n\")), mdx(\"h3\", {\n    \"id\": \"running-the-example\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#running-the-example\"\n  })), \"Running the example\"), mdx(\"p\", null, \"After build\\xADing the pre\\xADvi\\xADous im\\xADages, build and run the ex\\xADam\\xADple in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"vertx-elk\"), \" using the fol\\xADlow\\xADing com\\xADmand:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"hljs language-ebnf\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"hljs-attribute\"\n  }), \"docker-compose up\"), \"\\n\")), mdx(\"h3\", {\n    \"id\": \"the-demo\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#the-demo\"\n  })), \"The demo\"), mdx(\"p\", null, \"You can watch the demo in ac\\xADtion in the fol\\xADlow\\xADing screen\\xADcast:\"), mdx(\"div\", {\n    className: \"youtube-embed\"\n  }, mdx(\"iframe\", {\n    src: \"https://www.youtube.com/embed/8P-MgXSujes\",\n    frameBorder: \"0\",\n    allowFullScreen: true\n  })), mdx(\"h2\", {\n    \"id\": \"conclusion\"\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"aria-hidden\": true,\n    \"tabIndex\": -1,\n    \"className\": \"heading-anchor\",\n    \"href\": \"#conclusion\"\n  })), \"Conclusion\"), mdx(\"p\", null, \"The ELK stack is a pow\\xADer\\xADful set of tools that ease the ag\\xADgre\\xADga\\xADtion of logs com\\xADing from dis\\xADtrib\\xADuted ser\\xADvices into a cen\\xADtral server. Its main pil\\xADlar, Elas\\xADtic\\xADsearch, pro\\xADvides the in\\xADdex\\xADing and search ca\\xADpa\\xADbil\\xADi\\xADties of our log data. Also, it is ac\\xADcom\\xADpa\\xADnied by the con\\xADve\\xADnient input/out\\xADput com\\xADpo\\xADnents: Logstash, which can be flex\\xADi\\xADbly con\\xADfig\\xADured to ac\\xADcept dif\\xADfer\\xADent data sources; and Kibana, which can be cus\\xADtomized to present the in\\xADfor\\xADma\\xADtion in the most con\\xADve\\xADnient way.\"), mdx(\"p\", null, \"Logstash has been de\\xADsigned to work seam\\xADlessly with File\\xADbeat, the log ship\\xADper which rep\\xADre\\xADsents a ro\\xADbust so\\xADlu\\xADtion that can be adapted to our ap\\xADpli\\xADca\\xADtions with\\xADout hav\\xADing to make \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"sig\\xADnif\\xADi\\xADcant\"), \" changes to our ar\\xADchi\\xADtec\\xADture. In ad\\xADdi\\xADtion, Logstash can ac\\xADcept var\\xADied types of sources, fil\\xADter the data, and process it be\\xADfore de\\xADliv\\xADer\\xADing to Elas\\xADtic\\xADsearch. This flex\\xADi\\xADbil\\xADity comes with the price of hav\\xADing extra el\\xADe\\xADments in our log ag\\xADgre\\xADga\\xADtion pipeline, which can rep\\xADre\\xADsent an in\\xADcrease of pro\\xADcess\\xADing over\\xADhead or a point-\\u200Bof-failure. This ad\\xADdi\\xADtional over\\xADhead could be avoided if an ap\\xADpli\\xADca\\xADtion would be ca\\xADpa\\xADble of de\\xADliv\\xADer\\xADing its log out\\xADput di\\xADrectly to Elas\\xADtic\\xADsearch.\"), mdx(\"p\", null, \"Happy log\\xADging!\"));\n}\n\n;\nMDXContent.isMDXComponent = true;","renderedOutput":"<p>This post entry de­scribes a so­lu­tion to achieve cen­tral­ized log­ging of Vert.x ap­pli­ca­tions using the <a href=\"https://www.elastic.co/webinars/introduction-elk-stack\">ELK stack</a>, a set of tools in­clud­ing Logstash, Elas­tic­search, and Kibana that are well known to work to­gether seam­lessly.</p><h2 id=\"preamble\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#preamble\"></a>Preamble</h2><p>This post was writ­ten in con­text of the project ti­tled “<a href=\"https://summerofcode.withgoogle.com/projects/#4858492141699072\">De­vOps tool­ing for Vert.x ap­pli­ca­tions</a>”, one of the Vert.x projects tak­ing place dur­ing the 2016 edi­tion of <a href=\"https://summerofcode.withgoogle.com/about/\">Google Sum­mer of Code</a>, a pro­gram that aims to bring to­gether stu­dents with open source or­ga­ni­za­tions, in order to help them to gain ex­po­sure to soft­ware de­vel­op­ment prac­tices and real-​world chal­lenges.</p><h2 id=\"introduction\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#introduction\"></a>Introduction</h2><p>Cen­tral­ized log­ging is an im­por­tant topic while build­ing a Mi­croser­vices ar­chi­tec­ture and it is a step for­ward to adopt­ing the De­vOps cul­ture. Hav­ing an over­all so­lu­tion par­ti­tioned into a set of ser­vices dis­trib­uted across the In­ter­net can rep­re­sent a chal­lenge when try­ing to mon­i­tor the log out­put of each of them, hence, a tool that helps to ac­com­plish this re­sults very help­ful.</p><h2 id=\"overview\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#overview\"></a>Overview</h2><p>As shown in the di­a­gram below, the gen­eral cen­tral­ized log­ging so­lu­tion com­prises two main el­e­ments: the ap­pli­ca­tion server, which runs our Vert.x ap­pli­ca­tion; and a sep­a­rate server, host­ing the ELK stack. Both el­e­ments are linked by File­beat, a highly con­fig­urable tool ca­pa­ble of ship­ping our ap­pli­ca­tion logs to the Logstash in­stance, i.e., our gate­way to the ELK stack.</p><p><img src=\"/images/blog/centralized-logging-using-elk/elk-overview.svg\" alt=\"Overview of centralized logging with ELK\"/></p><h2 id=\"app-logging-configuration\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#app-logging-configuration\"></a>App logging configuration</h2><p>The ap­proach de­scribed here is based on a File­beat + Logstash con­fig­u­ra­tion, that means first we need to make sure our app logs to a file, whose records will be shipped to Logstash by File­beat. Luck­ily, Vert.x pro­vides the means to <a href=\"/docs/vertx-core/java/#_logging\">con­fig­ure</a> al­ter­na­tive log­ging frame­works (e.g., Log4j, Log4j2 and SLF4J) be­sides the de­fault JUL log­ging. How­ever, we can use File­beat in­de­pen­dently of the log­ging frame­work cho­sen.</p><h3 id=\"log4j-logging\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#log4j-logging\"></a>Log4j Logging</h3><p>The demo that ac­com­pa­nies this post re­lies on Log4j2 as the log­ging frame­work. We in­structed Vert.x to use this frame­work fol­low­ing the <a href=\"/docs/vertx-core/java/#_logging\">guide­lines</a> and we made sure our log­ging calls are made asyn­chro­nous, since we don’t want them to block our ap­pli­ca­tion. For this pur­pose, we opted for the <code>AsyncAppender</code> and this was in­cluded in the Log4J con­fig­u­ra­tion to­gether with the log out­put for­mat de­scribed in a XML con­fig­u­ra­tion avail­able in the ap­pli­ca­tion’s <em>Re­source</em> folder.</p><pre><code class=\"hljs language-xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Configuration</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Appenders</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">RollingFile</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;vertx_logs&quot;</span> <span class=\"hljs-attr\">append</span>=<span class=\"hljs-string\">&quot;true&quot;</span> <span class=\"hljs-attr\">fileName</span>=<span class=\"hljs-string\">&quot;/var/log/vertx.log&quot;</span> <span class=\"hljs-attr\">filePattern</span>=<span class=\"hljs-string\">&quot;/var/log/vertx/$${date:yyyy-MM}/vertx-%d{MM-dd-yyyy}-%i.log.gz&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">PatternLayout</span> <span class=\"hljs-attr\">pattern</span>=<span class=\"hljs-string\">&quot;%d{ISO8601} %-5p %c:%L - %m%n&quot;</span> /&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">RollingFile</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Async</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;vertx_async&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">AppenderRef</span> <span class=\"hljs-attr\">ref</span>=<span class=\"hljs-string\">&quot;vertx_logs&quot;</span>/&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Async</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Appenders</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Loggers</span>&gt;</span>\n    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">Root</span> <span class=\"hljs-attr\">level</span>=<span class=\"hljs-string\">&quot;DEBUG&quot;</span>&gt;</span>\n      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">AppenderRef</span> <span class=\"hljs-attr\">ref</span>=<span class=\"hljs-string\">&quot;vertx_async&quot;</span> /&gt;</span>\n    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Root</span>&gt;</span>\n  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Loggers</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">Configuration</span>&gt;</span>\n</code></pre><h3 id=\"filebeat-configuration\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#filebeat-configuration\"></a>Filebeat configuration</h3><p>Now that we have con­fig­ured the log out­put of our Vert.x ap­pli­ca­tion to be stored in the file sys­tem, we del­e­gate to File­beat the task of for­ward­ing the logs to the Logstash in­stance. File­beat can be con­fig­ured through a YAML file con­tain­ing the logs out­put lo­ca­tion and the pat­tern to in­ter­pret mul­ti­line logs (i.e., stack traces). Also, the Logstash out­put plug­in is con­fig­ured with the host lo­ca­tion and a se­cure con­nec­tion is en­forced using the cer­tifi­cate from the ma­chine host­ing Logstash. We set the <code>document_type</code> to the type of in­stance that this log be­longs to, which could later help us while in­dex­ing our logs in­side Elas­tic­search.</p><pre><code class=\"hljs language-yaml\"><span class=\"hljs-attr\">filebeat:</span>\n  <span class=\"hljs-attr\">prospectors:</span>\n    <span class=\"hljs-bullet\">-</span>\n      <span class=\"hljs-attr\">document_type:</span> <span class=\"hljs-string\">trader_dashboard</span>\n      <span class=\"hljs-attr\">paths:</span>\n        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">/var/log/vertx.log</span>\n      <span class=\"hljs-attr\">multiline:</span>\n        <span class=\"hljs-attr\">pattern:</span> <span class=\"hljs-string\">&quot;^[0-9]+&quot;</span>\n        <span class=\"hljs-attr\">negate:</span> <span class=\"hljs-literal\">true</span>\n        <span class=\"hljs-attr\">match:</span> <span class=\"hljs-string\">after</span>\n<span class=\"hljs-attr\">output:</span>\n  <span class=\"hljs-attr\">logstash:</span>\n    <span class=\"hljs-attr\">enabled:</span> <span class=\"hljs-literal\">true</span>\n    <span class=\"hljs-attr\">hosts:</span>\n      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">elk:5044</span>\n    <span class=\"hljs-attr\">timeout:</span> <span class=\"hljs-number\">15</span>\n    <span class=\"hljs-attr\">tls:</span>\n      <span class=\"hljs-attr\">insecure:</span> <span class=\"hljs-literal\">false</span>\n      <span class=\"hljs-attr\">certificate_authoritites:</span>\n        <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">/etc/pki/tls/certs/logstash-beats.crt</span>\n</code></pre><h2 id=\"elk-configuration\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#elk-configuration\"></a>ELK configuration</h2><p>To take fully ad­van­tage of the ELK stack with re­spect to Vert.x and our app logs, we need to con­fig­ure each of its in­di­vid­ual com­po­nents, namely Logstash, Elas­tic­search and Kibana.</p><h3 id=\"logstash\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#logstash\"></a>Logstash</h3><p>Logstash is the com­po­nent within the ELK stack that is in charge of ag­gre­gat­ing the logs from each of the sources and for­ward­ing them to the Elas­tic­search in­stance.<br/>\n<!-- -->Con­fig­ur­ing Logstash is straight­for­ward with the help of the spe­cific input and out­put plu­g­ins for Beats and Elas­tic­search, re­spec­tively.\nIn the pre­vi­ous sec­tion we men­tioned that File­beat could be eas­ily cou­pled with Logstash. Now, we see that this can be done by just spec­i­fy­ing <code>Beat</code> as the input plug­in and set the pa­ra­me­ters needed to be reached by our ship­pers (lis­ten­ing port, ssl key and cer­tifi­cate lo­ca­tion).</p><pre><code class=\"hljs language-bash\">input {\n  beats {\n    port =&gt; 5044\n    ssl =&gt; <span class=\"hljs-literal\">true</span>\n    ssl_certificate =&gt; <span class=\"hljs-string\">&quot;/etc/pki/tls/certs/logstash-beats.crt&quot;</span>\n    ssl_key =&gt; <span class=\"hljs-string\">&quot;/etc/pki/tls/private/logstash-beats.key&quot;</span>\n  }\n}\n</code></pre><p>Now that we are ready to re­ceive logs from the app, we can use Logstash fil­ter­ing ca­pa­bil­i­ties to spec­ify the for­mat of our logs and ex­tract the fields so they can be in­dexed more ef­fi­ciently by Elas­tic­search.<br/>\n<!-- -->The <code>grok</code> fil­ter­ing plug­in comes handy in this sit­u­a­tion. This plug­in al­lows to de­clare the logs for­mat using pre­de­fined and cus­tomized pat­terns based in reg­u­lar ex­pres­sions al­low­ing to de­clare new fields from the in­for­ma­tion ex­tracted from each log line. In the fol­low­ing block, we in­struct Logstash to rec­og­nize our Log4j pat­tern in­side a <code>message</code> field, which con­tains the log mes­sage shipped by File­beat. After that, the <code>date</code> fil­ter­ing plug­in parses the <code>timestamp</code> field ex­tracted in the pre­vi­ous step and re­places it for the one set by File­beat after read­ing the log out­put file.</p><pre><code class=\"hljs language-bash\">filter {\n  grok {\n    break_on_match =&gt; <span class=\"hljs-literal\">false</span>\n    match =&gt;  [ <span class=\"hljs-string\">&quot;message&quot;</span>, <span class=\"hljs-string\">&quot;%{LOG4J}&quot;</span>]\n  }\n  date{\n    match =&gt; [ <span class=\"hljs-string\">&quot;timestamp_string&quot;</span>, <span class=\"hljs-string\">&quot;ISO8601&quot;</span>]\n    remove_field =&gt; [ <span class=\"hljs-string\">&quot;timestamp_string&quot;</span> ]\n  }\n}\n</code></pre><p>The Log4j pat­tern is not in­cluded within the Logstash con­fig­u­ra­tion, how­ever, we can spec­ify it using pre­de­fined data for­mats shipped with Logstash and adapt it to the spe­cific log for­mats re­quired in our ap­pli­ca­tion, as shown next.</p><pre><code class=\"hljs language-ruby\"><span class=\"hljs-comment\"># Pattern to match our Log4j format</span>\nSPACING (?<span class=\"hljs-symbol\">:</span>[\\s]+)\nLOGGER (?<span class=\"hljs-symbol\">:</span>[a-zA-Z$_][a-zA-Z$_0-<span class=\"hljs-number\">9</span>]*\\.)*[a-zA-Z$_][a-zA-Z$_0-<span class=\"hljs-number\">9</span>]*\nLINE <span class=\"hljs-string\">%{INT}</span>?\nLOG4J <span class=\"hljs-string\">%{TIMESTAMP_ISO8601:timestamp_string}</span> <span class=\"hljs-string\">%{LOGLEVEL:log_level}</span><span class=\"hljs-string\">%{SPACING}</span><span class=\"hljs-string\">%{LOGGER:logger_name}</span><span class=\"hljs-symbol\">:<span class=\"hljs-string\">%{LINE:loc_line}</span></span> - <span class=\"hljs-string\">%{JAVALOGMESSAGE:log_message}</span>\n</code></pre><p>Fi­nally, we take a look at Logstash’s out­put con­fig­u­ra­tion. This sim­ply points to our elas­tic­search in­stance, in­structs it to pro­vide a list of all clus­ter nodes (<code>sniffing</code>), de­fines the name pat­tern for our in­dices, as­signs the doc­u­ment type ac­cord­ing to the meta­data com­ing from File­beat, and al­lows to de­fine a cus­tom index tem­plate for our data.</p><pre><code class=\"hljs language-puppet\"><span class=\"hljs-keyword\">output</span> {\n  elasticsearch {\n    <span class=\"hljs-attr\">hosts</span> =&gt; [<span class=\"hljs-string\">&quot;localhost&quot;</span>]\n    <span class=\"hljs-attr\">sniffing</span> =&gt; <span class=\"hljs-keyword\">true</span>\n    <span class=\"hljs-attr\">manage_template</span> =&gt; <span class=\"hljs-keyword\">true</span>\n    <span class=\"hljs-attr\">index</span> =&gt; <span class=\"hljs-string\">&quot;%{[@metadata][beat]}-%{+YYYY.MM.dd}&quot;</span>\n    <span class=\"hljs-attr\">document_type</span> =&gt; <span class=\"hljs-string\">&quot;%{[@metadata][type]}&quot;</span>\n    <span class=\"hljs-attr\">template</span> =&gt; <span class=\"hljs-string\">&quot;/etc/filebeat/vertx_app_filebeat.json&quot;</span>\n    <span class=\"hljs-attr\">template_overwrite</span> =&gt; <span class=\"hljs-keyword\">true</span>\n  }\n}\n</code></pre><h3 id=\"elasticsearch\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#elasticsearch\"></a>Elasticsearch</h3><p>Elas­tic­search is the cen­tral com­po­nent that en­ables the ef­fi­cient in­dex­ing and real-​time search ca­pa­bil­i­ties of the stack. To take the most ad­van­tage of Elas­tic­search, we can pro­vide an in­dex­ing tem­plate of our in­com­ing logs, which can help to op­ti­mize the data stor­age and match the queries is­sued by Kibana at a later point.<br/>\n<!-- -->In the ex­am­ple below, we see an index tem­plate that would be ap­plied to any index match­ing the pat­tern <code>filebeat-*</code>. Ad­di­tion­ally, we de­clare our new log fields <code>type</code>, <code>host</code>, <code>log_level</code>, <code>logger_name</code>, and <code>log_message</code>, which are set as <code>not_analyzed</code> ex­cept for the last two that are set as <code>analyzed</code> al­low­ing to per­form queries based on reg­u­lar ex­pres­sions and not re­stricted to query the full text.</p><pre><code class=\"hljs language-json\">{\n  <span class=\"hljs-attr\">&quot;mappings&quot;</span>: {\n    <span class=\"hljs-attr\">&quot;_default_&quot;</span>: {\n      <span class=\"hljs-attr\">&quot;_all&quot;</span>: {\n        <span class=\"hljs-attr\">&quot;enabled&quot;</span>: <span class=\"hljs-literal\">true</span>,\n        <span class=\"hljs-attr\">&quot;norms&quot;</span>: {\n          <span class=\"hljs-attr\">&quot;enabled&quot;</span>: <span class=\"hljs-literal\">false</span>\n        }\n      },\n      <span class=\"hljs-attr\">&quot;dynamic_templates&quot;</span>: [\n        {\n          <span class=\"hljs-attr\">&quot;template1&quot;</span>: {\n            <span class=\"hljs-attr\">&quot;mapping&quot;</span>: {\n              <span class=\"hljs-attr\">&quot;doc_values&quot;</span>: <span class=\"hljs-literal\">true</span>,\n              <span class=\"hljs-attr\">&quot;ignore_above&quot;</span>: <span class=\"hljs-number\">1024</span>,\n              <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span>,\n              <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;{dynamic_type}&quot;</span>\n            },\n            <span class=\"hljs-attr\">&quot;match&quot;</span>: <span class=\"hljs-string\">&quot;*&quot;</span>\n          }\n        }\n      ],\n      <span class=\"hljs-attr\">&quot;properties&quot;</span>: {\n        <span class=\"hljs-attr\">&quot;@timestamp&quot;</span>: {\n          <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;date&quot;</span>\n        },\n        <span class=\"hljs-attr\">&quot;offset&quot;</span>: {\n          <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;long&quot;</span>,\n          <span class=\"hljs-attr\">&quot;doc_values&quot;</span>: <span class=\"hljs-string\">&quot;true&quot;</span>\n        },\n        <span class=\"hljs-attr\">&quot;type&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;host&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;log_level&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;not_analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;logger_name&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;analyzed&quot;</span> },\n        <span class=\"hljs-attr\">&quot;log_message&quot;</span>: { <span class=\"hljs-attr\">&quot;type&quot;</span>: <span class=\"hljs-string\">&quot;string&quot;</span>, <span class=\"hljs-attr\">&quot;index&quot;</span>: <span class=\"hljs-string\">&quot;analyzed&quot;</span> }\n      }\n    }\n  },\n  <span class=\"hljs-attr\">&quot;settings&quot;</span>: {\n    <span class=\"hljs-attr\">&quot;index.refresh_interval&quot;</span>: <span class=\"hljs-string\">&quot;5s&quot;</span>\n  },\n  <span class=\"hljs-attr\">&quot;template&quot;</span>: <span class=\"hljs-string\">&quot;filebeat-*&quot;</span>\n}\n</code></pre><h3 id=\"kibana\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#kibana\"></a>Kibana</h3><p>Al­though we could fetch all our logs from Elas­tic­search through its API, Kibana is a pow­er­ful tool that al­lows a more friendly query and vi­su­al­iza­tion.\nBe­sides the op­tion to query our data through the avail­able in­dexed field names and search boxes al­low­ing typ­ing spe­cific queries, Kibana al­lows cre­at­ing our own <em>Vi­su­al­iza­tions</em> and <em>Dash­boards</em>. Com­bined, they rep­re­sent a pow­er­ful way to dis­play data and gain in­sight in a cus­tomized man­ner.\nThe ac­com­pa­nied demo ships with a cou­ple of sam­ple dash­boards and vi­su­al­iza­tions that take ad­van­tage of the log fields that we spec­i­fied in our index tem­plate and throw valu­able in­sight. This in­cludes: vi­su­al­iz­ing the num­ber of log mes­sages re­ceived by ELK, ob­serve the pro­por­tion of mes­sages that each log source pro­duces, and di­rectly find out the sources of error logs.</p><p><img src=\"/images/blog/centralized-logging-using-elk/kibana-dashboard.png\" alt=\"Kibana Dashboard&quot; width=&quot;550\"/></p><h2 id=\"log-shipping-challenge\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#log-shipping-challenge\"></a>Log shipping challenge</h2><p>The so­lu­tion pre­sented here re­lied on File­beat to ship log data to Logstash. How­ever, if you are fa­mil­iar with the Log4j frame­work you may be aware that there ex­ists a <em>Sock­e­tAp­pen­der</em> that al­lows to write log events di­rectly to a re­mote server using a TCP con­nec­tion. Al­though in­clud­ing the File­beat + Logstash com­bi­na­tion  may sound an un­nec­es­sary over­head to the log­ging pipeline, they pro­vide a num­ber of ben­e­fits in com­par­i­son to the Log4j socket al­ter­na­tive:</p><ul><li>The Sock­e­tAp­pen­der re­lies on the spe­cific se­ri­al­iza­tion of Log4j’s <em>Lo­gEvent</em> ob­jects, which is no an in­ter­change­able for­mat as JSON, which is used by the Beats so­lu­tion. Al­though there are <a href=\"https://github.com/majikthys/log4j2-logstash-jsonevent-layout\">at­tempts</a> to out­put the logs in a JSON for­mat for Logstash, it doesn’t sup­port mul­ti­line logs, which re­sults in mes­sages being split into dif­fer­ent events by Logstash. On the other hand, there is no of­fi­cial nor sta­ble <a href=\"https://www.elastic.co/guide/en/logstash/current/input-plugins.html\">input plugin</a> for Log4j ver­sion 2.</li><li>While en­abling Log4j’s async log­ging mode in an ap­pli­ca­tion del­e­gates log­ging op­er­a­tions to sep­a­rate threads, given their co­ex­is­tence in the same JVM there is still the risk of data loss in case of a sud­den JVM ter­mi­na­tion with­out proper log chan­nel clos­ing.</li><li>File­beat is a data ship­per de­signed to deal with many con­straints that arise in dis­trib­uted en­vi­ron­ments in a re­li­able man­ner, there­fore it pro­vides op­tions to tai­lor and scale this op­er­a­tion to our needs: the pos­si­bil­ity to load bal­ance be­tween mul­ti­ple Logstash in­stances, spec­ify the num­ber of si­mul­ta­ne­ous File­beat work­ers that ship log files, and spec­ify a com­pres­sion level in order to re­duce the con­sumed band­width. Be­sides that, logs can be shipped in spe­cific batch sizes, with max­i­mum amount of re­tries, and spec­i­fy­ing a con­nec­tion time­out.</li><li>Lastly, al­though File­beat can for­ward logs di­rectly to Elas­tic­search, using Logstash as an in­ter­me­di­ary of­fers the pos­si­bil­ity to col­lect logs from di­verse sources (e.g., sys­tem met­rics).</li></ul><h2 id=\"demo\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#demo\"></a>Demo</h2><p>This post is ac­com­pa­nied by a demo based on the Vert.x Mi­croser­vices <a href=\"http://vertx-lab.dynamis-technologies.com/\">work­shop</a>, where each of them is shipped in a Docker con­tainer sim­u­lat­ing a dis­trib­uted sys­tem com­posed of in­de­pen­dent ad­dress­able nodes.<br/>\n<!-- -->Also, the ELK stack is pro­vi­sioned using a pre­con­fig­ured Docker image by <a href=\"https://github.com/spujadas\">Sébastien Pu­jadas</a>.</p><p>Fol­low­ing the guide­lines in this post, this demo con­fig­ures each of the Mi­croser­vices of the work­shop, sets up a File­beat process on each of them to ship the logs to a cen­tral con­tainer host­ing the ELK stack.</p><h3 id=\"installation\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#installation\"></a>Installation</h3><p>In order to run this demo, it is nec­es­sary to have Docker in­stalled, then pro­ceed with:</p><ul><li>Cloning or down­load­ing the demo <a href=\"https://github.com/ricardohmon/vertx-elk\">repos­i­tory</a>.</li><li>Sep­a­rately, ob­tain­ing the source code of the <a href=\"https://github.com/ricardohmon/vertx-microservices-workshop/tree/elk-demo\">branch</a> of the Mi­croser­vices work­shop adapted for this demo.</li></ul><h3 id=\"building-the-example\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#building-the-example\"></a>Building the example</h3><p>The Docker im­ages be­long­ing to the Vert.x Mi­croser­vices work­shop need to be built sep­a­rately to this project be­fore this project can be launched.</p><h3 id=\"building-the-vertx-microservices-workshop-docker-images\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#building-the-vertx-microservices-workshop-docker-images\"></a>Building the Vert.x Microservices workshop Docker images.</h3><p>Build the <em>root</em> project and the <em>Trader Dash­board</em> fol­lowed by each of the mod­ules con­tained in the so­lu­tion folder. Issue the fol­low­ing com­mands for this:</p><pre><code class=\"hljs language-bash\">mvn clean install\n<span class=\"hljs-built_in\">cd</span> trader-dashboard\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../solution/audit-service\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../compulsive-traders\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../portfolio-service\nmvn package docker:build\n<span class=\"hljs-built_in\">cd</span> ../quote-generator/\nmvn package docker:build\n</code></pre><h3 id=\"running-the-example\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#running-the-example\"></a>Running the example</h3><p>After build­ing the pre­vi­ous im­ages, build and run the ex­am­ple in <code>vertx-elk</code> using the fol­low­ing com­mand:</p><pre><code class=\"hljs language-ebnf\"><span class=\"hljs-attribute\">docker-compose up</span>\n</code></pre><h3 id=\"the-demo\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#the-demo\"></a>The demo</h3><p>You can watch the demo in ac­tion in the fol­low­ing screen­cast:</p><div class=\"youtube-embed\"><iframe src=\"https://www.youtube.com/embed/8P-MgXSujes\" frameBorder=\"0\" allowfullscreen=\"\"></iframe></div><h2 id=\"conclusion\"><a aria-hidden=\"true\" tabindex=\"-1\" class=\"heading-anchor\" href=\"#conclusion\"></a>Conclusion</h2><p>The ELK stack is a pow­er­ful set of tools that ease the ag­gre­ga­tion of logs com­ing from dis­trib­uted ser­vices into a cen­tral server. Its main pil­lar, Elas­tic­search, pro­vides the in­dex­ing and search ca­pa­bil­i­ties of our log data. Also, it is ac­com­pa­nied by the con­ve­nient input/out­put com­po­nents: Logstash, which can be flex­i­bly con­fig­ured to ac­cept dif­fer­ent data sources; and Kibana, which can be cus­tomized to present the in­for­ma­tion in the most con­ve­nient way.</p><p>Logstash has been de­signed to work seam­lessly with File­beat, the log ship­per which rep­re­sents a ro­bust so­lu­tion that can be adapted to our ap­pli­ca­tions with­out hav­ing to make <em>sig­nif­i­cant</em> changes to our ar­chi­tec­ture. In ad­di­tion, Logstash can ac­cept var­ied types of sources, fil­ter the data, and process it be­fore de­liv­er­ing to Elas­tic­search. This flex­i­bil­ity comes with the price of hav­ing extra el­e­ments in our log ag­gre­ga­tion pipeline, which can rep­re­sent an in­crease of pro­cess­ing over­head or a point-​of-failure. This ad­di­tional over­head could be avoided if an ap­pli­ca­tion would be ca­pa­ble of de­liv­er­ing its log out­put di­rectly to Elas­tic­search.</p><p>Happy log­ging!</p>","scope":{}}},"prevPost":{"meta":{"title":"Vert.x 3.3.3 is released!","category":"releases","authors":[{"name":"Clement Escoffier","github_id":"cescoffier"}],"summary":"We have just released Vert.x 3.3.3, a bug fix release of Vert.x 3.3.x."},"date":"2016-09-12","slug":"vert-x-3-3-3-is-released"},"nextPost":{"meta":{"title":"Vert.x Blueprint Tutorials","category":"guides","authors":[{"name":"Eric Zhao","github_id":"sczyh30"}],"summary":"The Vert.x Blueprint project aims to provide guidelines to Vert.x users to implement various applications such as message-based applications and microservices."},"date":"2016-09-01","slug":"vert-x-blueprint-tutorials"},"relatedPosts":[{"meta":{"title":"Getting started with new fabric8 Vert.x Maven Plugin","category":"guides","authors":[{"name":"Kamesh Sampath","github_id":"kameshsampath"}],"summary":"The all new fabric8 Vert.x Maven Plugin allows you to setup, package, run, start, stop and redeploy easily with a very little configuration resulting in a less verbose pom.xml."},"date":"2016-12-07","slug":"getting-started-with-new-fabric8-vert-x-maven-plugin"},{"meta":{"title":"Vert.x featuring Continuous Delivery with Jenkins and Ansible","category":"guides","authors":[{"name":"Ricardo Hernandez","github_id":"ricardohmon"}],"summary":"This blog entry describes an approach to adopt Continuous Delivery for Vert.x applications using Jenkins and Ansible by taking advantage of the Jenkins Job DSL and Ansible plugins."},"date":"2016-09-28","slug":"vert-x-featuring-continuous-delivery-with-jenkins-and-ansible"},{"meta":{"title":"Unit and Integration Tests","category":"guides","authors":[{"name":"Clement Escoffier","github_id":"cescoffier"}],"summary":"Let’s refresh our mind about what we developed so far in the introduction to vert.x series. We forgot an important task. We didn’t test the API."},"date":"2015-08-03","slug":"unit-and-integration-tests"}]},"__N_SSG":true}