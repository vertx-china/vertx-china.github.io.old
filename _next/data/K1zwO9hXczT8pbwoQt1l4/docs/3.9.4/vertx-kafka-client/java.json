{"pageProps":{"slug":"3.9.4/vertx-kafka-client/java","title":"Vert.x Kafka client","fallbackGitHubStars":null,"toc":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#_using_the_vert_x_kafka_client\">Using the Vert.x Kafka client</a></li>\n<li><a href=\"#_creating_kafka_clients\">Creating Kafka clients</a></li>\n<li><a href=\"#_receiving_messages_from_a_topic_joining_a_consumer_group\">Receiving messages from a topic joining a consumer group</a></li>\n<li><a href=\"#_receiving_messages_from_a_topic_requesting_specific_partitions\">Receiving messages from a topic requesting specific partitions</a></li>\n<li><a href=\"#_receiving_messages_with_explicit_polling\">Receiving messages with explicit polling</a></li>\n<li><a href=\"#_changing_the_subscription_or_assignment\">Changing the subscription or assignment</a></li>\n<li><a href=\"#_getting_topic_partition_information\">Getting topic partition information</a></li>\n<li><a href=\"#_manual_offset_commit\">Manual offset commit</a></li>\n<li><a href=\"#_seeking_in_a_topic_partition\">Seeking in a topic partition</a></li>\n<li><a href=\"#_offset_lookup\">Offset lookup</a></li>\n<li><a href=\"#_message_flow_control\">Message flow control</a></li>\n<li><a href=\"#_closing_a_consumer\">Closing a consumer</a></li>\n<li><a href=\"#_sending_messages_to_a_topic\">Sending messages to a topic</a></li>\n<li><a href=\"#_sharing_a_producer\">Sharing a producer</a></li>\n<li><a href=\"#_closing_a_producer\">Closing a producer</a></li>\n<li><a href=\"#_getting_topic_partition_information_2\">Getting topic partition information</a></li>\n<li><a href=\"#_handling_errors\">Handling errors</a></li>\n<li><a href=\"#_automatic_clean_up_in_verticles\">Automatic clean-up in verticles</a></li>\n<li><a href=\"#_using_vert_x_serializersdeserializers\">Using Vert.x serializers/deserializers</a></li>\n<li><a href=\"#_rxjava_2_api\">RxJava 2 API</a></li>\n</ul>\n</div>","contents":"<h1>Vert.x Kafka client</h1>\n\n<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>This component provides a Kafka client for reading and sending messages from/to an <a href=\"https://kafka.apache.org/\">Apache Kafka</a> cluster.</p>\n</div>\n<div class=\"paragraph\">\n<p>As consumer, the API provides methods for subscribing to a topic partition receiving\nmessages asynchronously or reading them as a stream (even with the possibility to pause/resume the stream).</p>\n</div>\n<div class=\"paragraph\">\n<p>As producer, the API provides methods for sending message to a topic partition like writing on a stream.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_the_vert_x_kafka_client\"><a class=\"anchor\" href=\"#_using_the_vert_x_kafka_client\"></a>Using the Vert.x Kafka client</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>To use this component, add the following dependency to the dependencies section of your build descriptor:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Maven (in your <code>pom.xml</code>):</p>\n</li>\n</ul>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-xml\" data-lang=\"xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dependency</span>&gt;</span>\n <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">groupId</span>&gt;</span>io.vertx<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">groupId</span>&gt;</span>\n <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">artifactId</span>&gt;</span>vertx-kafka-client<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">artifactId</span>&gt;</span>\n <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">version</span>&gt;</span>3.9.4<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">version</span>&gt;</span>\n<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dependency</span>&gt;</span></code></pre>\n</div>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Gradle (in your <code>build.gradle</code> file):</p>\n</li>\n</ul>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-groovy\" data-lang=\"groovy\">compile io.<span class=\"hljs-string\">vertx:</span>vertx-kafka-<span class=\"hljs-string\">client:</span><span class=\"hljs-number\">3.9</span><span class=\"hljs-number\">.4</span></code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_creating_kafka_clients\"><a class=\"anchor\" href=\"#_creating_kafka_clients\"></a>Creating Kafka clients</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Creating consumers and producers is quite similar and on how it works using the native Kafka client library.</p>\n</div>\n<div class=\"paragraph\">\n<p>They need to be configured with a bunch of properties as described in the official\nApache Kafka documentation, for the <a href=\"https://kafka.apache.org/documentation/#newconsumerconfigs\">consumer</a> and\nfor the <a href=\"https://kafka.apache.org/documentation/#producerconfigs\">producer</a>.</p>\n</div>\n<div class=\"paragraph\">\n<p>To achieve that, a map can be configured with such properties passing it to one of the\nstatic creation methods exposed by <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html\">KafkaConsumer</a></code> and\n<code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html\">KafkaProducer</a></code></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.deserializer\"</span>, <span class=\"hljs-string\">\"org.apache.kafka.common.serialization.StringDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.deserializer\"</span>, <span class=\"hljs-string\">\"org.apache.kafka.common.serialization.StringDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"group.id\"</span>, <span class=\"hljs-string\">\"my_group\"</span>);\nconfig.put(<span class=\"hljs-string\">\"auto.offset.reset\"</span>, <span class=\"hljs-string\">\"earliest\"</span>);\nconfig.put(<span class=\"hljs-string\">\"enable.auto.commit\"</span>, <span class=\"hljs-string\">\"false\"</span>);\n\n<span class=\"hljs-comment\">// use consumer for interacting with Apache Kafka</span>\nKafkaConsumer&lt;String, String&gt; consumer = KafkaConsumer.create(vertx, config);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In the above example, a <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html\">KafkaConsumer</a></code> instance is created using\na map instance in order to specify the Kafka nodes list to connect (just one) and\nthe deserializers to use for getting key and value from each received message.</p>\n</div>\n<div class=\"paragraph\">\n<p>Likewise a producer can be created</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.serializer\"</span>, <span class=\"hljs-string\">\"org.apache.kafka.common.serialization.StringSerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.serializer\"</span>, <span class=\"hljs-string\">\"org.apache.kafka.common.serialization.StringSerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"acks\"</span>, <span class=\"hljs-string\">\"1\"</span>);\n\n<span class=\"hljs-comment\">// use producer for interacting with Apache Kafka</span>\nKafkaProducer&lt;String, String&gt; producer = KafkaProducer.create(vertx, config);</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_receiving_messages_from_a_topic_joining_a_consumer_group\"><a class=\"anchor\" href=\"#_receiving_messages_from_a_topic_joining_a_consumer_group\"></a>Receiving messages from a topic joining a consumer group</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>In order to start receiving messages from Kafka topics, the consumer can use the\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#subscribe-java.util.Set-\">subscribe</a></code> method for\nsubscribing to a set of topics being part of a consumer group (specified by the properties on creation).</p>\n</div>\n<div class=\"paragraph\">\n<p>It&#8217;s also possible to use the <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#subscribe-java.util.regex.Pattern-\">subscribe</a></code> method for\nsubscribing to more topics specifying a Java regex.</p>\n</div>\n<div class=\"paragraph\">\n<p>You also need to register a handler for handling incoming messages using the\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#handler-io.vertx.core.Handler-\">handler</a></code>.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">\"Processing key=\"</span> + record.key() + <span class=\"hljs-string\">\",value=\"</span> + record.value() +\n    <span class=\"hljs-string\">\",partition=\"</span> + record.partition() + <span class=\"hljs-string\">\",offset=\"</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">// subscribe to several topics with list</span>\nSet&lt;String&gt; topics = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\ntopics.add(<span class=\"hljs-string\">\"topic1\"</span>);\ntopics.add(<span class=\"hljs-string\">\"topic2\"</span>);\ntopics.add(<span class=\"hljs-string\">\"topic3\"</span>);\nconsumer.subscribe(topics);\n\n<span class=\"hljs-comment\">// or using a Java regex</span>\nPattern pattern = Pattern.compile(<span class=\"hljs-string\">\"topic\\\\d\"</span>);\nconsumer.subscribe(pattern);\n\n<span class=\"hljs-comment\">// or just subscribe to a single topic</span>\nconsumer.subscribe(<span class=\"hljs-string\">\"a-single-topic\"</span>);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The handler can be registered before or after the call to <code>subscribe()</code>; messages won&#8217;t be consumed until both\nmethods have been called. This allows you to call <code>subscribe()</code>, then <code>seek()</code> and finally <code>handler()</code> in\norder to only consume messages starting from a particular offset, for example.</p>\n</div>\n<div class=\"paragraph\">\n<p>A handler can also be passed during subscription to be aware of the subscription result and being notified when the operation\nis completed.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">\"Processing key=\"</span> + record.key() + <span class=\"hljs-string\">\",value=\"</span> + record.value() +\n    <span class=\"hljs-string\">\",partition=\"</span> + record.partition() + <span class=\"hljs-string\">\",offset=\"</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">// subscribe to several topics</span>\nSet&lt;String&gt; topics = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\ntopics.add(<span class=\"hljs-string\">\"topic1\"</span>);\ntopics.add(<span class=\"hljs-string\">\"topic2\"</span>);\ntopics.add(<span class=\"hljs-string\">\"topic3\"</span>);\nconsumer.subscribe(topics, ar -&gt; {\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"subscribed\"</span>);\n  } <span class=\"hljs-keyword\">else</span> {\n    System.out.println(<span class=\"hljs-string\">\"Could not subscribe \"</span> + ar.cause().getMessage());\n  }\n});\n\n<span class=\"hljs-comment\">// or just subscribe to a single topic</span>\nconsumer.subscribe(<span class=\"hljs-string\">\"a-single-topic\"</span>, ar -&gt; {\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"subscribed\"</span>);\n  } <span class=\"hljs-keyword\">else</span> {\n    System.out.println(<span class=\"hljs-string\">\"Could not subscribe \"</span> + ar.cause().getMessage());\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Using the consumer group way, the Kafka cluster assigns partitions to the consumer taking into account other connected\nconsumers in the same consumer group, so that partitions can be spread across them.</p>\n</div>\n<div class=\"paragraph\">\n<p>The Kafka cluster handles partitions re-balancing when a consumer leaves the group (so assigned partitions are free\nto be assigned to other consumers) or a new consumer joins the group (so it wants partitions to read from).</p>\n</div>\n<div class=\"paragraph\">\n<p>You can register handlers on a <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html\">KafkaConsumer</a></code> to be notified\nof the partitions revocations and assignments by the Kafka cluster using\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#partitionsRevokedHandler-io.vertx.core.Handler-\">partitionsRevokedHandler</a></code> and\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#partitionsAssignedHandler-io.vertx.core.Handler-\">partitionsAssignedHandler</a></code>.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">\"Processing key=\"</span> + record.key() + <span class=\"hljs-string\">\",value=\"</span> + record.value() +\n    <span class=\"hljs-string\">\",partition=\"</span> + record.partition() + <span class=\"hljs-string\">\",offset=\"</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">// registering handlers for assigned and revoked partitions</span>\nconsumer.partitionsAssignedHandler(topicPartitions -&gt; {\n\n  System.out.println(<span class=\"hljs-string\">\"Partitions assigned\"</span>);\n  <span class=\"hljs-keyword\">for</span> (TopicPartition topicPartition : topicPartitions) {\n    System.out.println(topicPartition.getTopic() + <span class=\"hljs-string\">\" \"</span> + topicPartition.getPartition());\n  }\n});\n\nconsumer.partitionsRevokedHandler(topicPartitions -&gt; {\n\n  System.out.println(<span class=\"hljs-string\">\"Partitions revoked\"</span>);\n  <span class=\"hljs-keyword\">for</span> (TopicPartition topicPartition : topicPartitions) {\n    System.out.println(topicPartition.getTopic() + <span class=\"hljs-string\">\" \"</span> + topicPartition.getPartition());\n  }\n});\n\n<span class=\"hljs-comment\">// subscribes to the topic</span>\nconsumer.subscribe(<span class=\"hljs-string\">\"test\"</span>, ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Consumer subscribed\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>After joining a consumer group for receiving messages, a consumer can decide to leave the consumer group in order to\nnot get messages anymore using <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#unsubscribe--\">unsubscribe</a></code></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.unsubscribe();</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You can add an handler to be notified of the result</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.unsubscribe(ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Consumer unsubscribed\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_receiving_messages_from_a_topic_requesting_specific_partitions\"><a class=\"anchor\" href=\"#_receiving_messages_from_a_topic_requesting_specific_partitions\"></a>Receiving messages from a topic requesting specific partitions</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Besides being part of a consumer group for receiving messages from a topic, a consumer can ask for a specific\ntopic partition. When the consumer is not part part of a consumer group the overall application cannot\nrely on the re-balancing feature.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can use <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#assign-java.util.Set-io.vertx.core.Handler-\">assign</a></code>\nin order to ask for specific partitions.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">\"key=\"</span> + record.key() + <span class=\"hljs-string\">\",value=\"</span> + record.value() +\n    <span class=\"hljs-string\">\",partition=\"</span> + record.partition() + <span class=\"hljs-string\">\",offset=\"</span> + record.offset());\n});\n\n<span class=\"hljs-comment\">//</span>\nSet&lt;TopicPartition&gt; topicPartitions = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\ntopicPartitions.add(<span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">\"test\"</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>));\n\n<span class=\"hljs-comment\">// requesting to be assigned the specific partition</span>\nconsumer.assign(topicPartitions, done -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (done.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Partition assigned\"</span>);\n\n    <span class=\"hljs-comment\">// requesting the assigned partitions</span>\n    consumer.assignment(done1 -&gt; {\n\n      <span class=\"hljs-keyword\">if</span> (done1.succeeded()) {\n\n        <span class=\"hljs-keyword\">for</span> (TopicPartition topicPartition : done1.result()) {\n          System.out.println(topicPartition.getTopic() + <span class=\"hljs-string\">\" \"</span> + topicPartition.getPartition());\n        }\n      }\n    });\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>As with <code>subscribe()</code>, the handler can be registered before or after the call to <code>assign()</code>;\nmessages won&#8217;t be consumed until both methods have been called. This allows you to call\n<code>assign()</code>, then <code>seek()</code> and finally <code>handler()</code> in\norder to only consume messages starting from a particular offset, for example.</p>\n</div>\n<div class=\"paragraph\">\n<p>Calling <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#assignment-io.vertx.core.Handler-\">assignment</a></code> provides\nthe list of the current assigned partitions.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_receiving_messages_with_explicit_polling\"><a class=\"anchor\" href=\"#_receiving_messages_with_explicit_polling\"></a>Receiving messages with explicit polling</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Other than using the internal polling mechanism in order to receive messages from Kafka, the client can subscribe to a\ntopic, avoiding to register the handler for getting the messages and then using the <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#poll-long-io.vertx.core.Handler-\">poll</a></code> method.</p>\n</div>\n<div class=\"paragraph\">\n<p>In this way, the user application is in charge to execute the poll for getting messages when it needs, for example after processing\nthe previous ones.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.subscribe(<span class=\"hljs-string\">\"test\"</span>, ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Consumer subscribed\"</span>);\n\n    vertx.setPeriodic(<span class=\"hljs-number\">1000</span>, timerId -&gt; {\n\n      consumer.poll(Duration.ofMillis(<span class=\"hljs-number\">100</span>), ar1 -&gt; {\n\n        <span class=\"hljs-keyword\">if</span> (ar1.succeeded()) {\n\n          KafkaConsumerRecords&lt;String, String&gt; records = ar1.result();\n          <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; records.size(); i++) {\n            KafkaConsumerRecord&lt;String, String&gt; record = records.recordAt(i);\n            System.out.println(<span class=\"hljs-string\">\"key=\"</span> + record.key() + <span class=\"hljs-string\">\",value=\"</span> + record.value() +\n              <span class=\"hljs-string\">\",partition=\"</span> + record.partition() + <span class=\"hljs-string\">\",offset=\"</span> + record.offset());\n          }\n        }\n      });\n\n    });\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>After subscribing successfully, the application start a periodic timer in order to execute the poll and getting messages\nfrom Kafka periodically.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_changing_the_subscription_or_assignment\"><a class=\"anchor\" href=\"#_changing_the_subscription_or_assignment\"></a>Changing the subscription or assignment</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>You can change the subscribed topics, or assigned partitions after you have started to consume messages, simply\nby calling <code>subscribe()</code> or <code>assign()</code> again.</p>\n</div>\n<div class=\"paragraph\">\n<p>Note that due to internal buffering of messages it is possible that the record handler will continue to\nobserve messages from the old subscription or assignment <em>after</em> the <code>subscribe()</code> or <code>assign()</code>\nmethod&#8217;s completion handler has been called. This is not the case for messages observed by the batch handler:\nOnce the completion handler has been called it will only observe messages read from the subscription or assignment.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_getting_topic_partition_information\"><a class=\"anchor\" href=\"#_getting_topic_partition_information\"></a>Getting topic partition information</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>You can call the <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#partitionsFor-java.lang.String-io.vertx.core.Handler-\">partitionsFor</a></code> to get information about\npartitions for a specified topic</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.partitionsFor(<span class=\"hljs-string\">\"test\"</span>, ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n\n    <span class=\"hljs-keyword\">for</span> (PartitionInfo partitionInfo : ar.result()) {\n      System.out.println(partitionInfo);\n    }\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In addition <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#listTopics-io.vertx.core.Handler-\">listTopics</a></code> provides all available topics\nwith related partitions</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.listTopics(ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n\n    Map&lt;String, List&lt;PartitionInfo&gt;&gt; map = ar.result();\n    map.forEach((topic, partitions) -&gt; {\n      System.out.println(<span class=\"hljs-string\">\"topic = \"</span> + topic);\n      System.out.println(<span class=\"hljs-string\">\"partitions = \"</span> + map.get(topic));\n    });\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_manual_offset_commit\"><a class=\"anchor\" href=\"#_manual_offset_commit\"></a>Manual offset commit</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>In Apache Kafka the consumer is in charge to handle the offset of the last read message.</p>\n</div>\n<div class=\"paragraph\">\n<p>This is executed by the commit operation executed automatically every time a bunch of messages are read\nfrom a topic partition. The configuration parameter <code>enable.auto.commit</code> must be set to <code>true</code> when the\nconsumer is created.</p>\n</div>\n<div class=\"paragraph\">\n<p>Manual offset commit, can be achieved with <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#commit-io.vertx.core.Handler-\">commit</a></code>.\nIt can be used to achieve <em>at least once</em> delivery to be sure that the read messages are processed before committing\nthe offset.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.commit(ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Last read message offset committed\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_seeking_in_a_topic_partition\"><a class=\"anchor\" href=\"#_seeking_in_a_topic_partition\"></a>Seeking in a topic partition</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Apache Kafka can retain messages for a long period of time and the consumer can seek inside a topic partition\nand obtain arbitrary access to the messages.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can use <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seek-io.vertx.kafka.client.common.TopicPartition-long-\">seek</a></code> to change the offset for reading at a specific\nposition</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">\"test\"</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// seek to a specific offset</span>\nconsumer.seek(topicPartition, <span class=\"hljs-number\">10</span>, done -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (done.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Seeking done\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>When the consumer needs to re-read the stream from the beginning, it can use <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToBeginning-io.vertx.kafka.client.common.TopicPartition-\">seekToBeginning</a></code></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">\"test\"</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// seek to the beginning of the partition</span>\nconsumer.seekToBeginning(Collections.singleton(topicPartition), done -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (done.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Seeking done\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Finally <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToEnd-io.vertx.kafka.client.common.TopicPartition-\">seekToEnd</a></code> can be used to come back at the end of the partition</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">\"test\"</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// seek to the end of the partition</span>\nconsumer.seekToEnd(Collections.singleton(topicPartition), done -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (done.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Seeking done\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Note that due to internal buffering of messages it is possible that the record handler will continue to\nobserve messages read from the original offset for a time <em>after</em> the <code>seek*()</code> method&#8217;s completion\nhandler has been called. This is not the case for messages observed by the batch handler: Once the\n<code>seek*()</code> completion handler has been called it will only observe messages read from the new offset.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_offset_lookup\"><a class=\"anchor\" href=\"#_offset_lookup\"></a>Offset lookup</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>You can use the beginningOffsets API introduced in Kafka 0.10.1.1 to get the first offset\nfor a given partition. In contrast to <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToBeginning-io.vertx.kafka.client.common.TopicPartition-\">seekToBeginning</a></code>,\nit does not change the consumer&#8217;s offset.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Set&lt;TopicPartition&gt; topicPartitions = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\nTopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition().setTopic(<span class=\"hljs-string\">\"test\"</span>).setPartition(<span class=\"hljs-number\">0</span>);\ntopicPartitions.add(topicPartition);\n\nconsumer.beginningOffsets(topicPartitions, done -&gt; {\n  <span class=\"hljs-keyword\">if</span>(done.succeeded()) {\n    Map&lt;TopicPartition, Long&gt; results = done.result();\n    results.forEach((topic, beginningOffset) -&gt;\n      System.out.println(<span class=\"hljs-string\">\"Beginning offset for topic=\"</span>+topic.getTopic()+<span class=\"hljs-string\">\", partition=\"</span>+\n        topic.getPartition()+<span class=\"hljs-string\">\", beginningOffset=\"</span>+beginningOffset));\n  }\n});\n\n<span class=\"hljs-comment\">// Convenience method for single-partition lookup</span>\nconsumer.beginningOffsets(topicPartition, done -&gt; {\n  <span class=\"hljs-keyword\">if</span>(done.succeeded()) {\n    Long beginningOffset = done.result();\n      System.out.println(<span class=\"hljs-string\">\"Beginning offset for topic=\"</span>+topicPartition.getTopic()+<span class=\"hljs-string\">\", partition=\"</span>+\n        topicPartition.getPartition()+<span class=\"hljs-string\">\", beginningOffset=\"</span>+beginningOffset);\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You can use the endOffsets API introduced in Kafka 0.10.1.1 to get the last offset\nfor a given partition. In contrast to <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#seekToEnd-io.vertx.kafka.client.common.TopicPartition-\">seekToEnd</a></code>,\nit does not change the consumer&#8217;s offset.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Set&lt;TopicPartition&gt; topicPartitions = <span class=\"hljs-keyword\">new</span> HashSet&lt;&gt;();\nTopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition().setTopic(<span class=\"hljs-string\">\"test\"</span>).setPartition(<span class=\"hljs-number\">0</span>);\ntopicPartitions.add(topicPartition);\n\nconsumer.endOffsets(topicPartitions, done -&gt; {\n  <span class=\"hljs-keyword\">if</span>(done.succeeded()) {\n    Map&lt;TopicPartition, Long&gt; results = done.result();\n    results.forEach((topic, endOffset) -&gt;\n      System.out.println(<span class=\"hljs-string\">\"End offset for topic=\"</span>+topic.getTopic()+<span class=\"hljs-string\">\", partition=\"</span>+\n        topic.getPartition()+<span class=\"hljs-string\">\", endOffset=\"</span>+endOffset));\n  }\n});\n\n<span class=\"hljs-comment\">// Convenience method for single-partition lookup</span>\nconsumer.endOffsets(topicPartition, done -&gt; {\n  <span class=\"hljs-keyword\">if</span>(done.succeeded()) {\n    Long endOffset = done.result();\n      System.out.println(<span class=\"hljs-string\">\"End offset for topic=\"</span>+topicPartition.getTopic()+<span class=\"hljs-string\">\", partition=\"</span>+\n        topicPartition.getPartition()+<span class=\"hljs-string\">\", endOffset=\"</span>+endOffset);\n  }\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You can use the offsetsForTimes API introduced in Kafka 0.10.1.1 to look up an offset by\ntimestamp, i.e. search parameter is an epoch timestamp and the call returns the lowest offset\nwith ingestion timestamp &gt;= given timestamp.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;TopicPartition, Long&gt; topicPartitionsWithTimestamps = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nTopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition().setTopic(<span class=\"hljs-string\">\"test\"</span>).setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// We are interested in the offset for data ingested 60 seconds ago</span>\n<span class=\"hljs-keyword\">long</span> timestamp = (System.currentTimeMillis() - <span class=\"hljs-number\">60000</span>);\n\ntopicPartitionsWithTimestamps.put(topicPartition, timestamp);\nconsumer.offsetsForTimes(topicPartitionsWithTimestamps, done -&gt; {\n  <span class=\"hljs-keyword\">if</span>(done.succeeded()) {\n    Map&lt;TopicPartition, OffsetAndTimestamp&gt; results = done.result();\n    results.forEach((topic, offset) -&gt;\n      System.out.println(<span class=\"hljs-string\">\"Offset for topic=\"</span>+topic.getTopic()+\n        <span class=\"hljs-string\">\", partition=\"</span>+topic.getPartition()+<span class=\"hljs-string\">\"\\n\"</span>+\n        <span class=\"hljs-string\">\", timestamp=\"</span>+timestamp+<span class=\"hljs-string\">\", offset=\"</span>+offset.getOffset()+\n        <span class=\"hljs-string\">\", offsetTimestamp=\"</span>+offset.getTimestamp()));\n\n  }\n});\n\n<span class=\"hljs-comment\">// Convenience method for single-partition lookup</span>\nconsumer.offsetsForTimes(topicPartition, timestamp, done -&gt; {\n  <span class=\"hljs-keyword\">if</span>(done.succeeded()) {\n    OffsetAndTimestamp offsetAndTimestamp = done.result();\n      System.out.println(<span class=\"hljs-string\">\"Offset for topic=\"</span>+topicPartition.getTopic()+\n        <span class=\"hljs-string\">\", partition=\"</span>+topicPartition.getPartition()+<span class=\"hljs-string\">\"\\n\"</span>+\n        <span class=\"hljs-string\">\", timestamp=\"</span>+timestamp+<span class=\"hljs-string\">\", offset=\"</span>+offsetAndTimestamp.getOffset()+\n        <span class=\"hljs-string\">\", offsetTimestamp=\"</span>+offsetAndTimestamp.getTimestamp());\n\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_message_flow_control\"><a class=\"anchor\" href=\"#_message_flow_control\"></a>Message flow control</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>A consumer can control the incoming message flow and pause/resume the read operation from a topic, e.g it\ncan pause the message flow when it needs more time to process the actual messages and then resume\nto continue message processing.</p>\n</div>\n<div class=\"paragraph\">\n<p>To achieve that you can use <code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#pause--\">pause</a></code> and\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#resume--\">resume</a></code>.</p>\n</div>\n<div class=\"paragraph\">\n<p>In the case of the partition-specific pause and resume it is possible that the record handler will continue to\nobserve messages from a paused partition for a time <em>after</em> the <code>pause()</code> method&#8217;s completion\nhandler has been called. This is not the case for messages observed by the batch handler: Once the\n<code>pause()</code> completion handler has been called it will only observe messages from those partitions which\nare not paused.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">TopicPartition topicPartition = <span class=\"hljs-keyword\">new</span> TopicPartition()\n  .setTopic(<span class=\"hljs-string\">\"test\"</span>)\n  .setPartition(<span class=\"hljs-number\">0</span>);\n\n<span class=\"hljs-comment\">// registering the handler for incoming messages</span>\nconsumer.handler(record -&gt; {\n  System.out.println(<span class=\"hljs-string\">\"key=\"</span> + record.key() + <span class=\"hljs-string\">\",value=\"</span> + record.value() +\n    <span class=\"hljs-string\">\",partition=\"</span> + record.partition() + <span class=\"hljs-string\">\",offset=\"</span> + record.offset());\n\n  <span class=\"hljs-comment\">// i.e. pause/resume on partition 0, after reading message up to offset 5</span>\n  <span class=\"hljs-keyword\">if</span> ((record.partition() == <span class=\"hljs-number\">0</span>) &amp;&amp; (record.offset() == <span class=\"hljs-number\">5</span>)) {\n\n    <span class=\"hljs-comment\">// pause the read operations</span>\n    consumer.pause(topicPartition, ar -&gt; {\n\n      <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n\n        System.out.println(<span class=\"hljs-string\">\"Paused\"</span>);\n\n        <span class=\"hljs-comment\">// resume read operation after a specific time</span>\n        vertx.setTimer(<span class=\"hljs-number\">5000</span>, timeId -&gt; {\n\n          <span class=\"hljs-comment\">// resume read operations</span>\n          consumer.resume(topicPartition);\n        });\n      }\n    });\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_closing_a_consumer\"><a class=\"anchor\" href=\"#_closing_a_consumer\"></a>Closing a consumer</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Call close to close the consumer. Closing the consumer closes any open connections and releases all consumer resources.</p>\n</div>\n<div class=\"paragraph\">\n<p>The close is actually asynchronous and might not complete until some time after the call has returned. If you want to be notified\nwhen the actual close has completed then you can pass in a handler.</p>\n</div>\n<div class=\"paragraph\">\n<p>This handler will then be called when the close has fully completed.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.close(res -&gt; {\n  <span class=\"hljs-keyword\">if</span> (res.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Consumer is now closed\"</span>);\n  } <span class=\"hljs-keyword\">else</span> {\n    System.out.println(<span class=\"hljs-string\">\"close failed\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_sending_messages_to_a_topic\"><a class=\"anchor\" href=\"#_sending_messages_to_a_topic\"></a>Sending messages to a topic</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>You can use  <code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#write-io.vertx.kafka.client.producer.KafkaProducerRecord-\">write</a></code> to send messages (records) to a topic.</p>\n</div>\n<div class=\"paragraph\">\n<p>The simplest way to send a message is to specify only the destination topic and the related value, omitting its key\nor partition, in this case the messages are sent in a round robin fashion across all the partitions of the topic.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) {\n\n  <span class=\"hljs-comment\">// only topic and message value are specified, round robin on destination partitions</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">\"test\"</span>, <span class=\"hljs-string\">\"message_\"</span> + i);\n\n  producer.write(record);\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You can receive message sent metadata like its topic, its destination partition and its assigned offset.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">5</span>; i++) {\n\n  <span class=\"hljs-comment\">// only topic and message value are specified, round robin on destination partitions</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">\"test\"</span>, <span class=\"hljs-string\">\"message_\"</span> + i);\n\n  producer.send(record, done -&gt; {\n\n    <span class=\"hljs-keyword\">if</span> (done.succeeded()) {\n\n      RecordMetadata recordMetadata = done.result();\n      System.out.println(<span class=\"hljs-string\">\"Message \"</span> + record.value() + <span class=\"hljs-string\">\" written on topic=\"</span> + recordMetadata.getTopic() +\n        <span class=\"hljs-string\">\", partition=\"</span> + recordMetadata.getPartition() +\n        <span class=\"hljs-string\">\", offset=\"</span> + recordMetadata.getOffset());\n    }\n\n  });\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>When you need to assign a partition to a message, you can specify its partition identifier\nor its key</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">10</span>; i++) {\n\n  <span class=\"hljs-comment\">// a destination partition is specified</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">\"test\"</span>, <span class=\"hljs-keyword\">null</span>, <span class=\"hljs-string\">\"message_\"</span> + i, <span class=\"hljs-number\">0</span>);\n\n  producer.write(record);\n}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Since the producers identifies the destination using key hashing, you can use that to guarantee that all\nmessages with the same key are sent to the same partition and retain the order.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\"><span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; <span class=\"hljs-number\">10</span>; i++) {\n\n  <span class=\"hljs-comment\">// i.e. defining different keys for odd and even messages</span>\n  <span class=\"hljs-keyword\">int</span> key = i % <span class=\"hljs-number\">2</span>;\n\n  <span class=\"hljs-comment\">// a key is specified, all messages with same key will be sent to the same partition</span>\n  KafkaProducerRecord&lt;String, String&gt; record =\n    KafkaProducerRecord.create(<span class=\"hljs-string\">\"test\"</span>, String.valueOf(key), <span class=\"hljs-string\">\"message_\"</span> + i);\n\n  producer.write(record);\n}</code></pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">注意</div>\n</td>\n<td class=\"content\">\nthe shared producer is created on the first <code>createShared</code> call and its configuration is defined at this moment,\nshared producer usage must use the same configuration.\n</td>\n</tr>\n</table>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_sharing_a_producer\"><a class=\"anchor\" href=\"#_sharing_a_producer\"></a>Sharing a producer</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Sometimes you want to share the same producer from within several verticles or contexts.</p>\n</div>\n<div class=\"paragraph\">\n<p>Calling <code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#createShared-io.vertx.core.Vertx-java.lang.String-java.util.Map-\">KafkaProducer.createShared</a></code>\nreturns a producer that can be shared safely.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">KafkaProducer&lt;String, String&gt; producer1 = KafkaProducer.createShared(vertx, <span class=\"hljs-string\">\"the-producer\"</span>, config);\n\n<span class=\"hljs-comment\">// Sometimes later you can close it</span>\nproducer1.close();</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The same resources (thread, connection) will be shared between the producer returned by this method.</p>\n</div>\n<div class=\"paragraph\">\n<p>When you are done with the producer, just close it, when all shared producers are closed, the resources will\nbe released for you.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_closing_a_producer\"><a class=\"anchor\" href=\"#_closing_a_producer\"></a>Closing a producer</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Call close to close the producer. Closing the producer closes any open connections and releases all producer resources.</p>\n</div>\n<div class=\"paragraph\">\n<p>The close is actually asynchronous and might not complete until some time after the call has returned. If you want to be notified\nwhen the actual close has completed then you can pass in a handler.</p>\n</div>\n<div class=\"paragraph\">\n<p>This handler will then be called when the close has fully completed.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">producer.close(res -&gt; {\n  <span class=\"hljs-keyword\">if</span> (res.succeeded()) {\n    System.out.println(<span class=\"hljs-string\">\"Producer is now closed\"</span>);\n  } <span class=\"hljs-keyword\">else</span> {\n    System.out.println(<span class=\"hljs-string\">\"close failed\"</span>);\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_getting_topic_partition_information_2\"><a class=\"anchor\" href=\"#_getting_topic_partition_information_2\"></a>Getting topic partition information</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>You can call the <code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#partitionsFor-java.lang.String-io.vertx.core.Handler-\">partitionsFor</a></code> to get information about\npartitions for a specified topic:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">producer.partitionsFor(<span class=\"hljs-string\">\"test\"</span>, ar -&gt; {\n\n  <span class=\"hljs-keyword\">if</span> (ar.succeeded()) {\n\n    <span class=\"hljs-keyword\">for</span> (PartitionInfo partitionInfo : ar.result()) {\n      System.out.println(partitionInfo);\n    }\n  }\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_handling_errors\"><a class=\"anchor\" href=\"#_handling_errors\"></a>Handling errors</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Errors handling (e.g timeout) between a Kafka client (consumer or producer) and the Kafka cluster is done using\n<code><a href=\"../../apidocs/io/vertx/kafka/client/consumer/KafkaConsumer.html#exceptionHandler-io.vertx.core.Handler-\">exceptionHandler</a></code> or\n<code><a href=\"../../apidocs/io/vertx/kafka/client/producer/KafkaProducer.html#exceptionHandler-io.vertx.core.Handler-\">exceptionHandler</a></code></p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">consumer.exceptionHandler(e -&gt; {\n  System.out.println(<span class=\"hljs-string\">\"Error = \"</span> + e.getMessage());\n});</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_automatic_clean_up_in_verticles\"><a class=\"anchor\" href=\"#_automatic_clean_up_in_verticles\"></a>Automatic clean-up in verticles</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>If you’re creating consumers and producer from inside verticles, those consumers and producers will be automatically\nclosed when the verticle is undeployed.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_using_vert_x_serializersdeserializers\"><a class=\"anchor\" href=\"#_using_vert_x_serializersdeserializers\"></a>Using Vert.x serializers/deserializers</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Vert.x Kafka client comes out of the box with serializers and deserializers for buffers, json object\nand json array.</p>\n</div>\n<div class=\"paragraph\">\n<p>In a consumer you can use buffers</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.deserializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.BufferDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.deserializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.BufferDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"group.id\"</span>, <span class=\"hljs-string\">\"my_group\"</span>);\nconfig.put(<span class=\"hljs-string\">\"auto.offset.reset\"</span>, <span class=\"hljs-string\">\"earliest\"</span>);\nconfig.put(<span class=\"hljs-string\">\"enable.auto.commit\"</span>, <span class=\"hljs-string\">\"false\"</span>);\n\n<span class=\"hljs-comment\">// Creating a consumer able to deserialize to json object</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.deserializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonObjectDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.deserializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonObjectDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"group.id\"</span>, <span class=\"hljs-string\">\"my_group\"</span>);\nconfig.put(<span class=\"hljs-string\">\"auto.offset.reset\"</span>, <span class=\"hljs-string\">\"earliest\"</span>);\nconfig.put(<span class=\"hljs-string\">\"enable.auto.commit\"</span>, <span class=\"hljs-string\">\"false\"</span>);\n\n<span class=\"hljs-comment\">// Creating a consumer able to deserialize to json array</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.deserializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonArrayDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.deserializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonArrayDeserializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"group.id\"</span>, <span class=\"hljs-string\">\"my_group\"</span>);\nconfig.put(<span class=\"hljs-string\">\"auto.offset.reset\"</span>, <span class=\"hljs-string\">\"earliest\"</span>);\nconfig.put(<span class=\"hljs-string\">\"enable.auto.commit\"</span>, <span class=\"hljs-string\">\"false\"</span>);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Or in a producer</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.serializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.BufferSerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.serializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.BufferSerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"acks\"</span>, <span class=\"hljs-string\">\"1\"</span>);\n\n<span class=\"hljs-comment\">// Creating a producer able to serialize to json object</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.serializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonObjectSerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.serializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonObjectSerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"acks\"</span>, <span class=\"hljs-string\">\"1\"</span>);\n\n<span class=\"hljs-comment\">// Creating a producer able to serialize to json array</span>\nconfig = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"key.serializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonArraySerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"value.serializer\"</span>, <span class=\"hljs-string\">\"io.vertx.kafka.client.serialization.JsonArraySerializer\"</span>);\nconfig.put(<span class=\"hljs-string\">\"acks\"</span>, <span class=\"hljs-string\">\"1\"</span>);</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You can also specify the serializers/deserializers at creation time:</p>\n</div>\n<div class=\"paragraph\">\n<p>In a consumer</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"group.id\"</span>, <span class=\"hljs-string\">\"my_group\"</span>);\nconfig.put(<span class=\"hljs-string\">\"auto.offset.reset\"</span>, <span class=\"hljs-string\">\"earliest\"</span>);\nconfig.put(<span class=\"hljs-string\">\"enable.auto.commit\"</span>, <span class=\"hljs-string\">\"false\"</span>);\n\n<span class=\"hljs-comment\">// Creating a consumer able to deserialize buffers</span>\nKafkaConsumer&lt;Buffer, Buffer&gt; bufferConsumer = KafkaConsumer.create(vertx, config, Buffer<span class=\"hljs-class\">.<span class=\"hljs-keyword\">class</span>, <span class=\"hljs-title\">Buffer</span>.<span class=\"hljs-title\">class</span>)</span>;\n\n<span class=\"hljs-comment\">// Creating a consumer able to deserialize json objects</span>\nKafkaConsumer&lt;JsonObject, JsonObject&gt; jsonObjectConsumer = KafkaConsumer.create(vertx, config, JsonObject<span class=\"hljs-class\">.<span class=\"hljs-keyword\">class</span>, <span class=\"hljs-title\">JsonObject</span>.<span class=\"hljs-title\">class</span>)</span>;\n\n<span class=\"hljs-comment\">// Creating a consumer able to deserialize json arrays</span>\nKafkaConsumer&lt;JsonArray, JsonArray&gt; jsonArrayConsumer = KafkaConsumer.create(vertx, config, JsonArray<span class=\"hljs-class\">.<span class=\"hljs-keyword\">class</span>, <span class=\"hljs-title\">JsonArray</span>.<span class=\"hljs-title\">class</span>)</span>;</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Or in a producer</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Map&lt;String, String&gt; config = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();\nconfig.put(<span class=\"hljs-string\">\"bootstrap.servers\"</span>, <span class=\"hljs-string\">\"localhost:9092\"</span>);\nconfig.put(<span class=\"hljs-string\">\"acks\"</span>, <span class=\"hljs-string\">\"1\"</span>);\n\n<span class=\"hljs-comment\">// Creating a producer able to serialize to buffers</span>\nKafkaProducer&lt;Buffer, Buffer&gt; bufferProducer = KafkaProducer.create(vertx, config, Buffer<span class=\"hljs-class\">.<span class=\"hljs-keyword\">class</span>, <span class=\"hljs-title\">Buffer</span>.<span class=\"hljs-title\">class</span>)</span>;\n\n<span class=\"hljs-comment\">// Creating a producer able to serialize to json objects</span>\nKafkaProducer&lt;JsonObject, JsonObject&gt; jsonObjectProducer = KafkaProducer.create(vertx, config, JsonObject<span class=\"hljs-class\">.<span class=\"hljs-keyword\">class</span>, <span class=\"hljs-title\">JsonObject</span>.<span class=\"hljs-title\">class</span>)</span>;\n\n<span class=\"hljs-comment\">// Creating a producer able to serialize to json arrays</span>\nKafkaProducer&lt;JsonArray, JsonArray&gt; jsonArrayProducer = KafkaProducer.create(vertx, config, JsonArray<span class=\"hljs-class\">.<span class=\"hljs-keyword\">class</span>, <span class=\"hljs-title\">JsonArray</span>.<span class=\"hljs-title\">class</span>)</span>;</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"_rxjava_2_api\"><a class=\"anchor\" href=\"#_rxjava_2_api\"></a>RxJava 2 API</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>The Kafka client provides an Rxified version of the original API.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-java\" data-lang=\"java\">Observable&lt;KafkaConsumerRecord&lt;String, Long&gt;&gt; observable = consumer.toObservable();\n\nobservable\n  .map(record -&gt; record.value())\n  .buffer(<span class=\"hljs-number\">256</span>)\n  .map(\n  list -&gt; list.stream().mapToDouble(n -&gt; n).average()\n).subscribe(val -&gt; {\n\n  <span class=\"hljs-comment\">// Obtained an average</span>\n\n});</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Unresolved directive in index.adoc - include::admin.adoc[]</p>\n</div>\n</div>\n</div>","version":"3.9.4"},"__N_SSG":true}